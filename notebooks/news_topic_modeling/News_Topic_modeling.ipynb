{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-qFVy2lBaqu"
   },
   "source": [
    "# News Topic modeling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNfMRWDbFXDJ"
   },
   "source": [
    "## I- Modules import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3QYNQcr-FQLs"
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.feature import  IDF, HashingTF,CountVectorizer\n",
    "from pyspark.ml import  Pipeline\n",
    "from math import ceil,log2\n",
    "from pyspark.ml.classification import LogisticRegression,NaiveBayes,LogisticRegressionModel\n",
    "from pyspark.sql.functions import col,explode,split\n",
    "\n",
    "import numpy as np\n",
    "from pyspark.ml.clustering import LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nj7Qu-EvK9_Y"
   },
   "source": [
    "## II- Spark context and session creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 219
    },
    "id": "aFZWn6-QBByS",
    "outputId": "cc18968f-50af-4a70-9d51-126be08a96c8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/06 06:07:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://node02.cm.cluster:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://node02:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>NewsTopicModeling</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fffa8faacd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = (SparkSession.builder\n",
    "    .master(\"spark://node02:7077\")\n",
    "    .appName(\"NewsTopicModeling\")\n",
    "    .getOrCreate()\n",
    "        )\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuV9CWoMN60A"
   },
   "source": [
    "## III- Dataframe preparing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Em4ZWvqhPoHt"
   },
   "source": [
    "### 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "xMI_45McvZto"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = spark.read.parquet(\"input/news.parquet\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4csdl2FOVf8"
   },
   "source": [
    "### 2. Partition and cache the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4EXrJ3GIBByT",
    "outputId": "0d866061-6fee-4bbb-fd79-84c946204d72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "PPBefKKqBByU"
   },
   "outputs": [],
   "source": [
    "num_partitions=4*20\n",
    "df= df.repartition(num_partitions).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ytFY1tjRBByU",
    "outputId": "cf5d7480-394e-43ac-e8e0-bc5cef64d4e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:================================================>       (69 + 11) / 80]\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4G5XozIiQTEx"
   },
   "source": [
    "### 3. Preview the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r86OcjwLv0EU",
    "outputId": "63e295fa-1b60-414b-f44f-3f8c8fd24a4b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1716608"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sfy_ivN4BByV",
    "outputId": "c374612e-8073-411f-a842-736cbe7eef50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+\n",
      "|category_label|description_filtered|\n",
      "+--------------+--------------------+\n",
      "|           7.0|orchard apple tre...|\n",
      "|           8.0|devolution sectio...|\n",
      "|           5.0|live leonard bloo...|\n",
      "|           4.0|top u general say...|\n",
      "|           9.0|daddy chore go by...|\n",
      "|           7.0|metamorphosis kaf...|\n",
      "|           8.0|soundbox miss 4ye...|\n",
      "|           8.0|90 covid19 patien...|\n",
      "|           6.0|appealingness med...|\n",
      "|           9.0|nurture tiddler e...|\n",
      "|           7.0|infinix zero 8 me...|\n",
      "|           5.0|new figure lake o...|\n",
      "|           6.0|medico get seriou...|\n",
      "|           8.0|bbc bias ruling c...|\n",
      "|           8.0|microsoft buy tik...|\n",
      "|           9.0|lie told moment baby|\n",
      "|           7.0|tinder automaton ...|\n",
      "|           9.0|yr one fair sex j...|\n",
      "|           4.0|president mnangag...|\n",
      "|           6.0|actually tap wate...|\n",
      "+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "awWri7zZQcOl",
    "outputId": "80402c12-f32a-483f-9ed0-ddad43eda4c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- category_label: double (nullable = true)\n",
      " |-- description_filtered: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMpXsNNsO_Z6"
   },
   "source": [
    "### 4. Convert filtered descriptions to arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Drqnhee0i26r",
    "outputId": "63a0cd7d-df8f-45c9-a6b5-ef7cf9bf7ebc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----------------------------------------------------------------------------------------------------------+\n",
      "|category_label|description_filtered                                                                                       |\n",
      "+--------------+-----------------------------------------------------------------------------------------------------------+\n",
      "|7.0           |[orchard, apple, tree, pulsation, powerbeats, pro, earbuds, crazy, tinny, today, exclusively, refurbished] |\n",
      "|8.0           |[devolution, section, staff, isolate, aureole, case]                                                       |\n",
      "|5.0           |[live, leonard, bloomfield, give, prescribed, covid19, update, 1pm, latest, subject, figure]               |\n",
      "|4.0           |[top, u, general, say, north, korea, military, posture, unchanged, amid, tension]                          |\n",
      "|9.0           |[daddy, chore, go, byebye]                                                                                 |\n",
      "|7.0           |[metamorphosis, kafkainspired, plot, bug]                                                                  |\n",
      "|8.0           |[soundbox, miss, 4yearold, girl, found, consortium, claude, elwood, shannon, que]                          |\n",
      "|8.0           |[90, covid19, patient, role, recoup, far, 7, active, case, merely, say, delhi, cm, kejriwal]               |\n",
      "|6.0           |[appealingness, medico, involve, utilization]                                                              |\n",
      "|9.0           |[nurture, tiddler, emotional, growth, part, 2]                                                             |\n",
      "|7.0           |[infinix, zero, 8, mediatek, helio, g90, soc, spotted, google, drama, listing, puzzler, television, leaked]|\n",
      "|5.0           |[new, figure, lake, ontario, provide, ray, light, hope, covid, fight]                                      |\n",
      "|6.0           |[medico, get, serious, happiness]                                                                          |\n",
      "|8.0           |[bbc, bias, ruling, confirms, article, exploring, covid19, pandemic, showed, antitrump, bias]              |\n",
      "|8.0           |[microsoft, buy, tiktok, much, every, bit, 30, billion]                                                    |\n",
      "|9.0           |[lie, told, moment, baby]                                                                                  |\n",
      "|7.0           |[tinder, automaton, choose, date, punter]                                                                  |\n",
      "|9.0           |[yr, one, fair, sex, journey, dark, side, yes]                                                             |\n",
      "|4.0           |[president, mnangagwa, defiant, citizen, protest, violation, using, zimbabweanlivesmatter]                 |\n",
      "|6.0           |[actually, tap, water, supply]                                                                             |\n",
      "+--------------+-----------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame with description_filtered as arrays\n",
    "df= df.withColumn('description_filtered', split(col('description_filtered'), ' '))\n",
    "# Show the new DataFrame\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RmBazOpQqXF"
   },
   "source": [
    "## IV- Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LjsTG0YLSyEn"
   },
   "source": [
    "### 1. Explode the filtered descriptions to get the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4qON2vCKBByX",
    "outputId": "3b8af783-1259-46dd-9346-ee5ee60033c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|        col|\n",
      "+-----------+\n",
      "|    orchard|\n",
      "|      apple|\n",
      "|       tree|\n",
      "|  pulsation|\n",
      "| powerbeats|\n",
      "|        pro|\n",
      "|    earbuds|\n",
      "|      crazy|\n",
      "|      tinny|\n",
      "|      today|\n",
      "|exclusively|\n",
      "|refurbished|\n",
      "| devolution|\n",
      "|    section|\n",
      "|      staff|\n",
      "|    isolate|\n",
      "|    aureole|\n",
      "|       case|\n",
      "|       live|\n",
      "|    leonard|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exploded_df=df.select(explode(df.description_filtered)).alias('words')\n",
    "exploded_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "DH41jOsrBByX"
   },
   "outputs": [],
   "source": [
    "#df=df.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MohTRQirTXD3"
   },
   "source": [
    "### 2. Get unique words in the filtered_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "2NbJFyQlBByX"
   },
   "outputs": [],
   "source": [
    "unique_words=exploded_df.distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-UjxthKU0Rq"
   },
   "source": [
    "### 3. Cache and show the unique words dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h1S8h39xBByX",
    "outputId": "8c884387-1347-4441-d313-56027086df18"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 19:=====================================>               (143 + 23) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|      col|\n",
      "+---------+\n",
      "| inverted|\n",
      "|    mammy|\n",
      "|    oscar|\n",
      "|   online|\n",
      "|    poppy|\n",
      "|    still|\n",
      "|   travel|\n",
      "|traveling|\n",
      "|  barrier|\n",
      "|  elevate|\n",
      "|  jewelry|\n",
      "|     pant|\n",
      "|      art|\n",
      "|recognize|\n",
      "|   patton|\n",
      "| carnegie|\n",
      "|  blossom|\n",
      "|    inner|\n",
      "|   90hour|\n",
      "|  quatern|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "unique_words=unique_words.cache()\n",
    "unique_words.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCb1pLl3VLOL"
   },
   "source": [
    "### 4. Get the vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dCakXZ3PBByX",
    "outputId": "e54847cd-6dce-4cf7-ffcb-7770061fcf18"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128622"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size=unique_words.count()\n",
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cV9aikKbYQzj"
   },
   "source": [
    "### 5. Define the CountVectorizer and IDF stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qYJp-K7O8pWN",
    "outputId": "dbdeed43-bf9e-40c4-ee66-ecd519909310"
   },
   "outputs": [],
   "source": [
    "# Define the HashingTF and IDF stages\n",
    "vectorizer = CountVectorizer(inputCol=\"description_filtered\", outputCol=\"raw_features\",vocabSize=vocabulary_size, minDF=3.0)\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74T1zTMRxKP8"
   },
   "source": [
    "## V- Models set up, training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmY4gqj5Q2w_"
   },
   "source": [
    "### 1. Set up LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "f8ya3gJ_PxLc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LDA_b18524a02c25"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#num_topics = 20\n",
    "#lda = LDA(k=num_topics, maxIter=10)\n",
    "lda = LDA(featuresCol=\"features\",seed=0)\n",
    "lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XT81OlVr5Ck1"
   },
   "source": [
    "### 2. Set up pipelines\n",
    "\n",
    "We will  set up the pipelines of the following transformations for Naive Bayes and Linear reggression\n",
    "\n",
    "- CountVectorizer\n",
    "- IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline_ccc22729faf7"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import CountVectorizer, IDF\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.ml.clustering import LDA\n",
    " \n",
    "# Create pipeline for LDA\n",
    "pipeline = Pipeline(stages=[vectorizer, idf, lda]) \n",
    "\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UD0gwMNf7yY7"
   },
   "source": [
    "### 3. Split the data\n",
    "\n",
    "First of all let us split the data into train and test set: 80% for train and 20% for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "pThnAKRy8LqP"
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "(train_set, test_set) = df.randomSplit([0.8, 0.2], seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M84xeE8i67YF"
   },
   "source": [
    "### 4. Create a function for model training\n",
    "\n",
    "Let us create a function which takes as argument a model that it trains and then returns the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AvRF-E1-7ncY",
    "outputId": "a361d112-8d8c-43c1-c926-d4a562e61afd"
   },
   "outputs": [],
   "source": [
    "def train_model(model):    \n",
    "    return model.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/06 06:12:04 WARN DAGScheduler: Broadcasting large task binary with size 1984.0 KiB\n",
      "24/06/06 06:12:08 WARN DAGScheduler: Broadcasting large task binary with size 1984.0 KiB\n",
      "24/06/06 06:12:08 WARN DAGScheduler: Broadcasting large task binary with size 2000.9 KiB\n",
      "24/06/06 06:12:11 WARN DAGScheduler: Broadcasting large task binary with size 2004.0 KiB\n",
      "24/06/06 06:12:16 WARN DAGScheduler: Broadcasting large task binary with size 2005.1 KiB\n",
      "24/06/06 06:12:18 WARN DAGScheduler: Broadcasting large task binary with size 2000.9 KiB\n",
      "24/06/06 06:12:19 WARN DAGScheduler: Broadcasting large task binary with size 2004.0 KiB\n",
      "24/06/06 06:12:23 WARN DAGScheduler: Broadcasting large task binary with size 2005.1 KiB\n",
      "24/06/06 06:12:27 WARN DAGScheduler: Broadcasting large task binary with size 2000.9 KiB\n",
      "24/06/06 06:12:28 WARN DAGScheduler: Broadcasting large task binary with size 2004.0 KiB\n",
      "24/06/06 06:12:30 WARN DAGScheduler: Broadcasting large task binary with size 2005.1 KiB\n",
      "24/06/06 06:12:34 WARN DAGScheduler: Broadcasting large task binary with size 2000.9 KiB\n",
      "24/06/06 06:12:35 WARN DAGScheduler: Broadcasting large task binary with size 2004.0 KiB\n",
      "24/06/06 06:12:37 WARN DAGScheduler: Broadcasting large task binary with size 2005.1 KiB\n",
      "24/06/06 06:12:39 WARN DAGScheduler: Broadcasting large task binary with size 2000.9 KiB\n",
      "24/06/06 06:12:39 WARN DAGScheduler: Broadcasting large task binary with size 2004.0 KiB\n",
      "24/06/06 06:12:41 WARN DAGScheduler: Broadcasting large task binary with size 2005.1 KiB\n",
      "24/06/06 06:12:43 WARN DAGScheduler: Broadcasting large task binary with size 2000.9 KiB\n",
      "24/06/06 06:12:44 WARN DAGScheduler: Broadcasting large task binary with size 2004.0 KiB\n",
      "24/06/06 06:12:46 WARN DAGScheduler: Broadcasting large task binary with size 2005.1 KiB\n",
      "24/06/06 06:12:47 WARN DAGScheduler: Broadcasting large task binary with size 2000.9 KiB\n",
      "24/06/06 06:12:47 WARN DAGScheduler: Broadcasting large task binary with size 2004.0 KiB\n",
      "24/06/06 06:12:49 WARN DAGScheduler: Broadcasting large task binary with size 2005.1 KiB\n",
      "24/06/06 06:12:52 WARN DAGScheduler: Broadcasting large task binary with size 2000.9 KiB\n",
      "24/06/06 06:12:53 WARN DAGScheduler: Broadcasting large task binary with size 2004.0 KiB\n",
      "24/06/06 06:12:56 WARN DAGScheduler: Broadcasting large task binary with size 2005.1 KiB\n",
      "24/06/06 06:12:58 WARN DAGScheduler: Broadcasting large task binary with size 2000.9 KiB\n",
      "24/06/06 06:12:59 WARN DAGScheduler: Broadcasting large task binary with size 2004.0 KiB\n",
      "24/06/06 06:13:06 WARN DAGScheduler: Broadcasting large task binary with size 2005.1 KiB\n",
      "24/06/06 06:13:09 WARN DAGScheduler: Broadcasting large task binary with size 2000.9 KiB\n",
      "24/06/06 06:13:09 WARN DAGScheduler: Broadcasting large task binary with size 2004.0 KiB\n",
      "24/06/06 06:13:11 WARN DAGScheduler: Broadcasting large task binary with size 2005.1 KiB\n",
      "24/06/06 06:13:12 WARN DAGScheduler: Broadcasting large task binary with size 2000.9 KiB\n",
      "24/06/06 06:13:13 WARN DAGScheduler: Broadcasting large task binary with size 2004.0 KiB\n",
      "24/06/06 06:13:16 WARN DAGScheduler: Broadcasting large task binary with size 2005.1 KiB\n",
      "24/06/06 06:13:20 WARN DAGScheduler: Broadcasting large task binary with size 2000.9 KiB\n",
      "24/06/06 06:13:20 WARN DAGScheduler: Broadcasting large task binary with size 2004.0 KiB\n",
      "24/06/06 06:13:22 WARN DAGScheduler: Broadcasting large task binary with size 2005.1 KiB\n",
      "24/06/06 06:13:24 WARN DAGScheduler: Broadcasting large task binary with size 2000.9 KiB\n",
      "24/06/06 06:13:24 WARN DAGScheduler: Broadcasting large task binary with size 2004.0 KiB\n",
      "24/06/06 06:13:26 WARN DAGScheduler: Broadcasting large task binary with size 2005.1 KiB\n",
      "24/06/06 06:13:30 WARN DAGScheduler: Broadcasting large task binary with size 2000.9 KiB\n",
      "24/06/06 06:13:30 WARN DAGScheduler: Broadcasting large task binary with size 2004.0 KiB\n",
      "24/06/06 06:13:32 WARN DAGScheduler: Broadcasting large task binary with size 2005.1 KiB\n",
      "24/06/06 06:13:37 WARN DAGScheduler: Broadcasting large task binary with size 2000.9 KiB\n",
      "24/06/06 06:13:38 WARN DAGScheduler: Broadcasting large task binary with size 2004.0 KiB\n",
      "24/06/06 06:13:43 WARN DAGScheduler: Broadcasting large task binary with size 2005.1 KiB\n",
      "24/06/06 06:13:45 WARN DAGScheduler: Broadcasting large task binary with size 2000.9 KiB\n",
      "24/06/06 06:13:46 WARN DAGScheduler: Broadcasting large task binary with size 2004.0 KiB\n",
      "24/06/06 06:13:47 WARN DAGScheduler: Broadcasting large task binary with size 2005.1 KiB\n",
      "24/06/06 06:13:49 WARN DAGScheduler: Broadcasting large task binary with size 2000.9 KiB\n",
      "24/06/06 06:13:49 WARN DAGScheduler: Broadcasting large task binary with size 2004.0 KiB\n",
      "24/06/06 06:13:52 WARN DAGScheduler: Broadcasting large task binary with size 2005.1 KiB\n",
      "24/06/06 06:13:53 WARN DAGScheduler: Broadcasting large task binary with size 2000.9 KiB\n",
      "24/06/06 06:13:54 WARN DAGScheduler: Broadcasting large task binary with size 2004.0 KiB\n",
      "24/06/06 06:13:56 WARN DAGScheduler: Broadcasting large task binary with size 2005.1 KiB\n",
      "24/06/06 06:14:01 WARN DAGScheduler: Broadcasting large task binary with size 2000.9 KiB\n",
      "24/06/06 06:14:02 WARN DAGScheduler: Broadcasting large task binary with size 2004.0 KiB\n",
      "24/06/06 06:14:04 WARN DAGScheduler: Broadcasting large task binary with size 2005.1 KiB\n",
      "24/06/06 06:14:05 WARN DAGScheduler: Broadcasting large task binary with size 2000.9 KiB\n",
      "24/06/06 06:14:05 WARN DAGScheduler: Broadcasting large task binary with size 2004.0 KiB\n",
      "24/06/06 06:14:07 WARN DAGScheduler: Broadcasting large task binary with size 2005.1 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PipelineModel_6308ba4e1161"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_model=train_model(pipeline)\n",
    "fitted_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Visualize the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73411"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_vectirizer=fitted_model.stages[0]\n",
    "vocabulary= fitted_vectirizer.vocabulary\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new', 'photo', 'state', 'trump', 'day', 'nt', 'say', 'woman', 'get', 'make']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|topic|         termIndices|         termWeights|\n",
      "+-----+--------------------+--------------------+\n",
      "|    0|[137, 4, 2, 7, 31...|[0.00416672987347...|\n",
      "|    1|[3, 107, 36, 195,...|[0.00435582030622...|\n",
      "|    2|[16, 30, 0, 57, 1...|[0.00500547082609...|\n",
      "|    3|[4, 1, 14, 11, 26...|[0.00423027191759...|\n",
      "|    4|[27, 2, 0, 47, 74...|[0.00264409013447...|\n",
      "|    5|[35, 187, 114, 0,...|[0.00352678941107...|\n",
      "|    6|[100, 0, 21, 53, ...|[0.00365710313344...|\n",
      "|    7|[230, 328, 3, 438...|[0.00399745479961...|\n",
      "|    8|[1, 0, 8, 33, 7, ...|[0.00347085298628...|\n",
      "|    9|[21, 26, 56, 312,...|[0.00446111456976...|\n",
      "+-----+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topics = fitted_model.stages[-1].describeTopics()   \n",
    "topics.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['space',\n",
       "  'day',\n",
       "  'state',\n",
       "  'woman',\n",
       "  'administration',\n",
       "  'national',\n",
       "  'love',\n",
       "  'best',\n",
       "  'tree',\n",
       "  'aeronautics'],\n",
       " ['trump',\n",
       "  'change',\n",
       "  'donald',\n",
       "  'climate',\n",
       "  'pope',\n",
       "  'photo',\n",
       "  'food',\n",
       "  'take',\n",
       "  'right',\n",
       "  'say']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_rdd = topics.rdd\n",
    "topics_words = topics_rdd\\\n",
    "       .map(lambda row: row['termIndices'])\\\n",
    "       .map(lambda idx_list: [vocabulary[idx] for idx in idx_list])\\\n",
    "       .collect()\n",
    "topics_words[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic: 0\n",
      "*************************\n",
      "space\n",
      "day\n",
      "state\n",
      "woman\n",
      "administration\n",
      "national\n",
      "love\n",
      "best\n",
      "tree\n",
      "aeronautics\n",
      "*************************\n",
      "topic: 1\n",
      "*************************\n",
      "trump\n",
      "change\n",
      "donald\n",
      "climate\n",
      "pope\n",
      "photo\n",
      "food\n",
      "take\n",
      "right\n",
      "say\n",
      "*************************\n",
      "topic: 2\n",
      "*************************\n",
      "covid19\n",
      "coronavirus\n",
      "new\n",
      "case\n",
      "r\n",
      "2020\n",
      "bank\n",
      "year\n",
      "u\n",
      "ha\n",
      "*************************\n",
      "topic: 3\n",
      "*************************\n",
      "day\n",
      "photo\n",
      "5\n",
      "video\n",
      "wedding\n",
      "make\n",
      "way\n",
      "new\n",
      "person\n",
      "nt\n",
      "*************************\n",
      "topic: 4\n",
      "*************************\n",
      "american\n",
      "state\n",
      "new\n",
      "child\n",
      "white\n",
      "sexual\n",
      "problem\n",
      "law\n",
      "nt\n",
      "learn\n",
      "*************************\n",
      "topic: 5\n",
      "*************************\n",
      "police\n",
      "officer\n",
      "hour\n",
      "new\n",
      "nt\n",
      "say\n",
      "trump\n",
      "photo\n",
      "man\n",
      "like\n",
      "*************************\n",
      "topic: 6\n",
      "*************************\n",
      "great\n",
      "new\n",
      "bank\n",
      "news\n",
      "house\n",
      "state\n",
      "york\n",
      "trump\n",
      "one\n",
      "dog\n",
      "*************************\n",
      "topic: 7\n",
      "*************************\n",
      "clinton\n",
      "hillary\n",
      "trump\n",
      "monophosphate\n",
      "deoxyadenosine\n",
      "photo\n",
      "san\n",
      "greater\n",
      "state\n",
      "joe\n",
      "*************************\n",
      "topic: 8\n",
      "*************************\n",
      "photo\n",
      "new\n",
      "get\n",
      "home\n",
      "woman\n",
      "re\n",
      "girl\n",
      "trial\n",
      "10\n",
      "marriage\n",
      "*************************\n",
      "topic: 9\n",
      "*************************\n",
      "bank\n",
      "wedding\n",
      "marriage\n",
      "ceremony\n",
      "nt\n",
      "india\n",
      "state\n",
      "new\n",
      "reserve\n",
      "way\n",
      "*************************\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in enumerate(topics_words):\n",
    "    print(\"topic: {}\".format(idx))\n",
    "    print(\"*\"*25)\n",
    "    for word in topic:\n",
    "       print(word)\n",
    "    print(\"*\"*25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get topics distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the training and test data\n",
    "train_set_transformed = fitted_model.transform(train_set)\n",
    "test_set_transformed = fitted_model.transform(test_set)\n",
    "\n",
    "# Get the LDA model from the pipeline model\n",
    "lda_model = fitted_model.stages[-1]\n",
    "\n",
    "# Extract the topic distributions\n",
    "train_topic_distributions = train_set_transformed.select(\"description_filtered\", \"topicDistribution\")\n",
    "test_topic_distributions = test_set_transformed.select(\"description_filtered\", \"topicDistribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/06 06:28:16 WARN DAGScheduler: Broadcasting large task binary with size 7.5 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|description_filtered                                                                                             |topicDistribution                                                                                                                                                                                                      |\n",
      "+-----------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[10, credit, score, truth, myth]                                                                                 |[0.002880521471769548,0.0028922344307042774,0.0029195398771760073,0.0029035587861105223,0.002897057865845022,0.0029069731092104182,0.3141132327298987,0.00283864611508934,0.00288177356053457,0.6627664620536615]      |\n",
      "|[10, thing, need, bring, interview]                                                                              |[0.003478041750515058,0.003491952247163347,0.003524824521497796,0.5437272306243047,0.0034979892388212037,0.003509665816446669,0.003458242869452248,0.0034274161864106573,0.42842113031735707,0.0034635064280312366]    |\n",
      "|[10, way, freelance, life, different, day, job]                                                                  |[0.734916714693847,0.0023442325983587674,0.0023663688710159384,0.24638523546026167,0.0023481283378728635,0.002356061586560801,0.0023216717574061105,0.002300741753685778,0.0023357222253365707,0.002325122715654366]   |\n",
      "|[12, famous, logo, evolved, time, infographic]                                                                   |[0.22967948276375086,0.0022203375409754703,0.0022411904612058314,0.18722797847046901,0.002223945741235779,0.002231436105669838,0.5675823258940248,0.002179098642177585,0.0022121246666736297,0.002202079713817081]     |\n",
      "|[20000, worth, cigarette, tobacco, seized, dublin, port]                                                         |[0.6353046544784426,0.0016045775992523784,0.3519054649524665,0.0016107714347579631,0.0016072821458608046,0.0016127812128193982,0.0015891071995738177,0.0015750071087291563,0.001598867937658603,0.0015914859304386754] |\n",
      "|[2024, g60, bmw, m5, go, full, electric, 1000, hp, paultanorg]                                                   |[0.2925652711861887,0.0012138571993764362,0.001225333652145775,0.0012185147940229843,0.4853688529582218,0.0012199943482939435,0.07255634417169084,0.0011914611488171984,0.14223645191724268,0.0012039186239996837]     |\n",
      "|[3, dividend, investing, tip, earn, thousand]                                                                    |[0.002151114559665225,0.18895010280941377,0.002180229896788149,0.22568628886371708,0.0021634958529514743,0.00217081232357198,0.5702839541322058,0.0021198167473856964,0.0021519629419947785,0.002142221872306005]      |\n",
      "|[4, reason, check, score, even, dont, plan, borrow, money, near, future]                                         |[0.0013298078671906968,0.06640582254323026,0.0013478233824294045,0.0013404038482645322,0.001337407474714725,0.34250316265729314,0.0013223742410991633,0.0013104390242012845,0.001330356677152385,0.5817724022844243]   |\n",
      "|[4, step, take, victim, identity, theft]                                                                         |[0.002484975936007809,0.002494930713652785,0.0025183550610352002,0.002504599871964148,0.6605565677223066,0.0025076841142831425,0.0024708270469663575,0.0024486029096004018,0.31953892580695237,0.002474530817231131]   |\n",
      "|[401k, fee, disclosure, aha, moment, come, november]                                                             |[0.195357127127113,0.0015782159719315134,0.0015929908914110895,0.0015841657702436865,0.0015806975014254355,0.0015860872336783878,0.19561961774945658,0.0015488332488476008,0.0015723069033407545,0.597979957602552]    |\n",
      "|[42, rise, new, business, premium, help, industry, clock, decent, growth]                                        |[0.0014319446111983479,0.0014378011542224285,0.7336962269778738,0.09697417261013305,0.0014402466535124502,0.0014451442408383495,0.001423927422590559,0.1592919828223741,0.00143248947916522,0.0014260640280917484]     |\n",
      "|[500, representative, 27, nation, including, top, regulator, central, banker, met, dozen, time, year]            |[0.0010762636722774826,0.3179003924227643,0.4723884117447733,0.0010847913863623452,0.001082396991870146,0.0010860995029725274,0.0010701924537108718,0.001060587706804671,0.0010766093132081583,0.2021742548052561]     |\n",
      "|[5th8th, grader, need, know, money]                                                                              |[0.003548675463562746,0.003562930529382183,0.46356079959257007,0.0035769794403117516,0.003569051187806999,0.0035810490963431476,0.003528716146130429,0.0034968995777086617,0.0035501078288335407,0.5080247911373504]   |\n",
      "|[8, way, get, people, take, seriously]                                                                           |[0.0030120608304428824,0.003024500504798162,0.003052843999521266,0.4573405087103088,0.5185538122757674,0.003039693845814168,0.002995190257080786,0.002968291010054439,0.003013394806812187,0.002999703759399978]       |\n",
      "|[83rd, annual, general, meeting, tamilnad, mercantile, bank, tmb, today, turned, nonevent, contentious]          |[0.001113518542673789,0.22456579410398272,0.7665270098727767,0.0011223666931588117,0.0011199097678508024,0.0011237084055162392,0.0011073579161631915,0.0010973577013324081,0.0011140333113064673,0.001108943685238844] |\n",
      "|[aaa, study, find, nearautonomous, driverassist, system, remain, flawed]                                         |[0.002119380860608107,0.980899197071854,0.002147982947353008,0.0021361122738015256,0.0021315480346499843,0.002138796910357622,0.002107454808364507,0.0020885466918020277,0.0021202125641296933,0.0021107678370794383]  |\n",
      "|[according, moody, low, capital, level, remain, key, credit, weakness, publicsector, bank]                       |[0.0011767187589600762,0.25774842156078975,0.0801476016463903,0.0011860209114420478,0.19030180361984644,0.001187487927436485,0.0011701836568836466,0.0011595973935502794,0.0011771363029117795,0.4647450282217893]     |\n",
      "|[according, ordinance, every, appeal, act, ha, made, within, 45, day, date, irdai, order]                        |[0.28961761349890675,0.0010793900306135446,0.0010894733426333176,0.0010835502150110608,0.0010811329695138891,0.0010848031509731032,0.0010689441789322335,0.31388673586845606,0.0010753766091730907,0.38893298013578703]|\n",
      "|[account, maintenance, charge, proposed, lowcost, pension, scheme, drastically, reduced, provide, safety, people]|[0.0010346418373587383,0.0010388909668603771,0.6295065031580482,0.0010428400089467793,0.15696155906006995,0.001044113567536544,0.0010288765545444407,0.0010195623048179629,0.0010350179077856392,0.20628799463403147]  |\n",
      "|[addition, west, bengal, also, request, reserve, bank, india, rbi, increase, additional, credit, limit, msmes]   |[9.392189849675287E-4,9.430170774736892E-4,9.51957917038702E-4,9.466326017668382E-4,0.1194336682375112,9.477907755946537E-4,0.08801727757299423,0.13955177362581134,9.395646468613305E-4,0.6473290985599806]           |\n",
      "+-----------------------------------------------------------------------------------------------------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/06 06:28:17 WARN DAGScheduler: Broadcasting large task binary with size 7.5 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|description_filtered                                                                                                                                                        |topicDistribution                                                                                                                                                                                                     |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[aiming, tackle, inflationary, pressure, reserve, bank, today, increased, key, statutory, deposit, ratio, bank, one]                                                        |[9.308050176460804E-4,9.346102801649792E-4,9.434760576826612E-4,9.381751442244003E-4,9.362106585549308E-4,9.393359306187638E-4,0.6184789510822547,9.172886872896255E-4,9.311723482502723E-4,0.3740499747933134]       |\n",
      "|[airline, airport, push, covid, testing, quarantine, hit, traffic]                                                                                                          |[0.0017245028972979431,0.001731432957482351,0.5367070147448069,0.18130010287186324,0.26993990634967524,0.0017403656280078857,0.0017148112287566743,0.0016994755290503979,0.0017250832079900795,0.0017173045850692585] |\n",
      "|[amid, stress, rising, bank, credit, portfolio, reserve, bank, india, rbi, tuesday, proposed, guideline, enable]                                                            |[9.9681420913349E-4,0.00100070747983115,0.5144391203404063,0.0010045338049719259,0.06810684899898165,0.0010057663683363351,9.911505159221048E-4,9.821978844461773E-4,9.970231402468327E-4,0.4104758372577239]         |\n",
      "|[amp, chief, tightlipped, executive, departure]                                                                                                                             |[0.002408056741727111,0.33966677704191506,0.0024404628950130446,0.002427199274287979,0.002421761118394691,0.6410612936222811,0.002394530897947195,0.0023729409340355763,0.0024089665110395395,0.0023980109633587416]  |\n",
      "|[andhra, bank, ha, reported, 212, per, cent, increase, net, profit, r, 14109, crore, quarter, ended, june, 2007, compared]                                                  |[7.888292246830686E-4,7.920313193423139E-4,0.9627511395778745,7.950654823736001E-4,7.933345984564263E-4,0.030943144536410668,7.844063839586766E-4,7.773496014886038E-4,7.89125268496423E-4,7.855740069157307E-4]      |\n",
      "|[apple, supplier, foxconn, post, betterthanexpected, second, quarter, profit]                                                                                               |[0.0014650677717504834,0.14210477593319246,0.7232931441221416,0.0014766752849311518,0.0014734532870820328,0.0014785042944802785,0.1243399316341304,0.0014437483348961721,0.0014656892046653715,0.001459010132730013]  |\n",
      "|[apple, watch, evidence, gang, four, becoming, bank]                                                                                                                        |[0.30803678647321775,0.002075724520467192,0.27468654394350944,0.21422244786507375,0.002079182542422052,0.002086298665821245,0.002055919658059013,0.0020372952751123293,0.0020682407102367885,0.19065156034608025]     |\n",
      "|[arthveda, fund, management, pe, arm, dewan, housing, finance, limited, dhfl, ha, tied, credit, analysis, research, ltd]                                                    |[8.215188157147702E-4,8.247747048228673E-4,8.326541499620233E-4,8.279414273602621E-4,8.261664257991493E-4,8.289620762304222E-4,0.5619099777900995,8.094941137071581E-4,8.217701597384833E-4,0.4314967403365654]       |\n",
      "|[axis, trustee, provide, facility, agency, service, ifsc, banking, unit, ecb, transaction, trusteeship, service]                                                            |[9.905865207785107E-4,9.946054691538342E-4,0.20917313240513716,9.98430484948559E-4,0.175097528977037,9.996740524802555E-4,9.851024708955015E-4,9.761559338459699E-4,9.909843810288305E-4,0.6087937993046945]          |\n",
      "|[bank, continued, issue, certificate, deposit, cd, today, meet, yearend, deposit, target, demand, mutual]                                                                   |[9.991102769040688E-4,0.0010032167848330934,0.0010126270312239012,0.12333908296096072,0.0010048507698106274,0.0010082502665667975,0.8686537749178249,9.846042327574796E-4,9.994916093381955E-4,9.949911497800963E-4]  |\n",
      "|[bank, parking, fund, security, qualifying, maintenance, statutory, liquidity, ratio, slr, also, mutual]                                                                    |[9.724238765565725E-4,9.763738205258618E-4,9.855786521823773E-4,9.801235495074177E-4,0.10197335697046338,9.813268062606453E-4,0.797863836653052,9.583198517641021E-4,9.728035191347959E-4,0.09333585630055281]        |\n",
      "|[bank, recorded, net, profit, r, 13315, crore, corresponding, quarter, last, fiscal, indusind, bank, said, filing]                                                          |[9.607427819013465E-4,9.646307645159698E-4,0.9913504858557917,9.68342610856298E-4,9.662370219880523E-4,9.695288437735098E-4,9.553611775837021E-4,9.467649870716362E-4,9.611074548947594E-4,9.567985016230669E-4]      |\n",
      "|[bank, reduced, borrowing, way, certificate, deposit, cd, finance, ministry, issued, norm, required]                                                                        |[0.0010413313544142021,0.0010455404726669119,0.17037417895192752,0.0010495852682596198,0.0010473208880966856,0.0010508473766475369,0.6439678114606007,0.0010261780535750767,0.0010417243104843634,0.17835548186332745]|\n",
      "|[bank, turned, best, class, trader, indian, secondary, market, sticking, strictly, sell, peak]                                                                              |[0.0010745451092524824,0.23486968430232905,0.001089065937339399,0.0010829837591996385,0.15634684336600588,0.0010843315036123708,0.37422506243187925,0.05141091317793515,0.17774647469488117,0.001070095717565695]     |\n",
      "|[based, new, recommendation, tax, devolution, state, work, r, 3948, lakh, crore, fiveyear, period]                                                                          |[0.0011192195587365174,0.0011237622985248708,0.35555748128104997,0.0011280825348644605,0.0011256367316667365,0.0011295780425338235,0.28275292410357117,0.001103033836581265,0.0011196288365984538,0.35384065277587273]|\n",
      "|[berkshire, hathaway, profit, surge, despite, near10bn, writedown]                                                                                                          |[0.0018018242615960268,0.001809205633245997,0.2510373534585087,0.0018160715566540885,0.28065137114434463,0.0018183585362234883,0.4556933106844031,0.001775616160155903,0.0018024927886344964,0.0017943957762334667]   |\n",
      "|[bp, plan, 59, billion, share, buy, back, criminal, fine, aim, boost, lagging, stock, report]                                                                               |[0.16990888708935922,9.518544183723611E-4,0.7043815853365243,9.555209932617525E-4,9.534019922559134E-4,9.56647743014182E-4,0.1190654309922099,9.341894727700164E-4,9.483588596257788E-4,9.441231026066167E-4]         |\n",
      "|[bryan, fite, missouri, man, find, centuryold, whiskey, bottle, attic, video]                                                                                               |[0.0011660723261775223,0.1275839647390093,0.0011818814537770362,0.37439305986452354,0.0011727026388675746,0.3088767046463604,0.0011595034881975751,0.001149080744281691,0.18215581714337925,0.0011612129554260484]    |\n",
      "|[bsnl, launch, mobile, service, vijoynagar]                                                                                                                                 |[0.003059340693140598,0.003071587579350689,0.5610418782251486,0.4144985752760165,0.003076770798242933,0.003087212627010694,0.0030423084962606676,0.0030151687281834306,0.003060409031956721,0.0030467485446890865]    |\n",
      "|[car, care, product, market, research, report, product, solvent, type, consumption, application, distribution, channel, global, forecast, 2025, cumulative, impact, covid19]|[7.162164293184866E-4,7.190863380887393E-4,0.6758549800697484,7.218560630064115E-4,7.202913829269032E-4,7.227381232074869E-4,0.22140542702881363,7.05764721122571E-4,7.165078703226228E-4,0.09771713197344477]        |\n",
      "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the topic distributions for the training set\n",
    "train_topic_distributions.show(truncate=False)\n",
    "\n",
    "# Show the topic distributions for the test set\n",
    "test_topic_distributions.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results={}\n",
    "num_topics_range=[20, 25, 30, 35, 40, 45, 50]\n",
    "\n",
    "for num_topics in num_topics_range:\n",
    "    print('LDA for k={}'.format(num_topics))\n",
    "    # Create LDA\n",
    "    lda = LDA(featuresCol=\"features\",seed=0)\n",
    "    # Create pipeline for LDA\n",
    "    pipeline = Pipeline(stages=[vectorizer, idf, lda])\n",
    "    print('Model training')\n",
    "    # Train the model\n",
    "    fitted_model=train_model(pipeline)\n",
    "    print('Done')\n",
    "    \n",
    "    train_set_transformed = fitted_model.transform(train_set)\n",
    "    test_set_transformed = fitted_model.transform(test_set)\n",
    "    train_lp,test_lp=evaluate_model(fitted_model,data_transformed=[train_set_transformed,test_set_transformed])\n",
    "    results[num_topics]=\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-fBEB1f9aRD"
   },
   "source": [
    "### 5. Define a function to evaluate the model\n",
    "\n",
    "The function takes as parameter a fitted model, evaluates the model on train and test split and then return the train and test performance. The accuracy is the metric used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate model and get best parameters\n",
    "def evaluate_model(fitted_model,data_transformed=[train_set_transformed,test_set_transformed]):\n",
    "    \n",
    "    print('Evaluating the model on training set')\n",
    "    train_lp = fitted_model.logPerplexity(data_transformed[0])\n",
    "\n",
    "    print('Evaluating the model on test set')\n",
    "    test_lp = fitted_model.logPerplexity(data_transformed[1])\n",
    "    \n",
    "    print(\"The upper bound on perplexity for train set: \" + str(train_lp))\n",
    "    print(\"The upper bound on perplexity for test set: \" + str(test_lp))\n",
    "    return train_lp, test_lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model on training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/06 07:44:58 WARN DAGScheduler: Broadcasting large task binary with size 1984.8 KiB\n",
      "24/06/06 07:45:59 WARN DAGScheduler: Broadcasting large task binary with size 1985.5 KiB\n",
      "24/06/06 07:46:52 WARN DAGScheduler: Broadcasting large task binary with size 1985.5 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model on test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/06 08:12:36 WARN DAGScheduler: Broadcasting large task binary with size 1984.8 KiB\n",
      "24/06/06 08:12:56 WARN DAGScheduler: Broadcasting large task binary with size 1985.5 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The upper bound on perplexity for train set: 9.078096971523154\n",
      "The upper bound on perplexity for test set: 9.135707712569403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(9.078096971523154, 9.135707712569403)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lp,test_lp=evaluate_model(fitted_model.stages[-1])\n",
    "train_lp,test_lp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[20, 25, 30, 35, 40, 45, 50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yG6dMBjzLXWA"
   },
   "source": [
    "### 6. Create a function which takes pipelines and train the models, evaluate them and then return the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "808-IeqCNb1v"
   },
   "source": [
    "We remark that\n",
    "- Naive Bayes\n",
    "- Logistic regression\n",
    "\n",
    "We can then conclude that t\n",
    "- he two models set a good performance on both training and test set.\n",
    "- The Logistic regression models outperforms the Naive Bayes model\n",
    "\n",
    "In the next section, we will tune the parameters of the Naive bayes to get the best parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xkME6ByNOegG"
   },
   "source": [
    "## VI- Logistic regression hyperparameters tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAWi0NqwSzgp"
   },
   "source": [
    "### 1. Pipeline creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wtq5K0JbOdpD"
   },
   "outputs": [],
   "source": [
    "# Define parameter grids for Logistic regresion grid search\n",
    "reg_values = np.logspace(-4, 4, num=100)\n",
    "l1_ratios = np.linspace(0, 1, num=10)\n",
    "\n",
    "paramGrid_lr=paramGrid_lr.addGrid(lr.regParam, reg_values).build()\n",
    "\n",
    "# Create Cross-validation for Logistic Regression\n",
    "cv_lr = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid_lr,\n",
    "                        evaluator=MulticlassClassificationEvaluator(labelCol=\"category_label\", predictionCol=\"prediction\", metricName=\"accuracy\"),\n",
    "                        numFolds=3, parallelism=1)\n",
    "\n",
    "\n",
    "# Create pipeline for Logistic Regression\n",
    "pipeline_lr = Pipeline(stages=[hashingTF, idf, cv_lr])\n",
    "\n",
    "pipeline_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XhMJxEzS87h"
   },
   "source": [
    "### 2. Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4bSLe3K5TL1L"
   },
   "outputs": [],
   "source": [
    "results=train_and_evaluate_models(model_pipelines=[pipeline_lr],model_names=[\"Logistic Regression\"])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUlLvsWVTkDy"
   },
   "source": [
    "### 3. Get the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k5rCb_boTk3e"
   },
   "outputs": [],
   "source": [
    "fitted_model=results['fitted_model']\n",
    "\n",
    "# Get the best model\n",
    "best_model = fitted_model.stages[-1].bestModel\n",
    "\n",
    "# Print the best parameters\n",
    "print(f\"Best parameters for Logistic regression:\")\n",
    "\n",
    "for param, value in best_model.extractParamMap().items():\n",
    "     print(f\"  {param.name}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEH0OfIqUxOg"
   },
   "source": [
    "### 4. Save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xX4pmvAVBByZ",
    "outputId": "843aa553-e419-43ba-dbb3-3ebb1a67f454"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/04 20:03:43 WARN TaskSetManager: Stage 216 contains a task of very large size (33450 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "best_model.save('output/news_categorization_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnFsw8x5Vyy2"
   },
   "source": [
    "## VII- Summary\n",
    "\n",
    "In this notebook we have studied two models for our news categorization task. There are Naive Bayes and Logistic regression.\n",
    "\n",
    " Our study reveals that the Logistic regression was the one with best performance.\n",
    "\n",
    " Then we tunned the Logistic regression hyperparameters using grid search and then we find the best model that we save.\n",
    "\n",
    " The next step of our work will be to ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NSyD5awwBByb"
   },
   "outputs": [],
   "source": [
    "#df.unpersist()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
