{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-qFVy2lBaqu"
   },
   "source": [
    "# News categorization\n",
    "\n",
    "In this notebook we are going to build a Machine Learning model for news categorization.\n",
    "\n",
    "Our dataset is the one we preprocessed before, which has two columns:\n",
    "\n",
    "- **description_filtered** which is the filtered description after performing cleaning, tokenization, lemmatization and stopword removal on the description of the news\n",
    "- **category_label** which is a numeric value that represents the category of our label.\n",
    "\n",
    "We converted the dataset format from csv to parquet.\n",
    "\n",
    "We are going to study **Logistic regression** with word embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNfMRWDbFXDJ"
   },
   "source": [
    "## I- Modules import\n",
    "\n",
    "Let us import the modules we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T02:15:45.505253Z",
     "iopub.status.busy": "2024-06-23T02:15:45.504565Z",
     "iopub.status.idle": "2024-06-23T02:15:46.023748Z",
     "shell.execute_reply": "2024-06-23T02:15:46.021815Z",
     "shell.execute_reply.started": "2024-06-23T02:15:45.505188Z"
    },
    "id": "3QYNQcr-FQLs"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml import  Pipeline\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.sql.functions import col,split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nj7Qu-EvK9_Y"
   },
   "source": [
    "## II- Spark context and session creation\n",
    "\n",
    "Let us create a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T02:15:46.026048Z",
     "iopub.status.busy": "2024-06-23T02:15:46.025252Z",
     "iopub.status.idle": "2024-06-23T02:15:56.951888Z",
     "shell.execute_reply": "2024-06-23T02:15:56.950006Z",
     "shell.execute_reply.started": "2024-06-23T02:15:46.026011Z"
    },
    "id": "aFZWn6-QBByS",
    "outputId": "b7430067-1724-411c-c9fb-aa0e1cf8140e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/28 22:05:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/06/28 22:05:38 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://node11.cm.cluster:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>NewsCategorization</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fffc16fa070>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = (SparkSession.builder\n",
    "    .master('local[*]')\n",
    "    .appName(\"NewsCategorization\")\n",
    "    .config(\"spark.driver.memory\", '320g')\\\n",
    "    .config(\"spark.driver.memoryOverhead\", \"500g\")\\\n",
    "    .getOrCreate()\n",
    "        )\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuV9CWoMN60A"
   },
   "source": [
    "## III- Dataframe preparing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Em4ZWvqhPoHt"
   },
   "source": [
    "### 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T02:15:56.963902Z",
     "iopub.status.busy": "2024-06-23T02:15:56.959615Z",
     "iopub.status.idle": "2024-06-23T02:16:01.314805Z",
     "shell.execute_reply": "2024-06-23T02:16:01.313439Z",
     "shell.execute_reply.started": "2024-06-23T02:15:56.963813Z"
    },
    "id": "xMI_45McvZto",
    "outputId": "7b2ef733-bdeb-4756-b088-efe035e50be6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Load the ata\n",
    "df = spark.read.parquet(\"models/word_embedding/logistic_regression/news.parquet\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4csdl2FOVf8"
   },
   "source": [
    "### 2. Partition and cache the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T02:16:01.317045Z",
     "iopub.status.busy": "2024-06-23T02:16:01.316598Z",
     "iopub.status.idle": "2024-06-23T02:16:02.579837Z",
     "shell.execute_reply": "2024-06-23T02:16:02.578585Z",
     "shell.execute_reply.started": "2024-06-23T02:16:01.317007Z"
    },
    "id": "4EXrJ3GIBByT",
    "outputId": "ddd03fd8-a9c6-436c-abe7-a1828a821abe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the current numbe rof RDD partitions\n",
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T02:16:02.582957Z",
     "iopub.status.busy": "2024-06-23T02:16:02.581700Z",
     "iopub.status.idle": "2024-06-23T02:16:02.588443Z",
     "shell.execute_reply": "2024-06-23T02:16:02.587059Z",
     "shell.execute_reply.started": "2024-06-23T02:16:02.582905Z"
    },
    "id": "PPBefKKqBByU"
   },
   "outputs": [],
   "source": [
    "# Repartitionning: Use 4 partitions per core\n",
    "num_partitions=4*40\n",
    "df= df.repartition(num_partitions).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T02:16:02.590615Z",
     "iopub.status.busy": "2024-06-23T02:16:02.590186Z",
     "iopub.status.idle": "2024-06-23T02:16:02.604214Z",
     "shell.execute_reply": "2024-06-23T02:16:02.602633Z",
     "shell.execute_reply.started": "2024-06-23T02:16:02.590581Z"
    },
    "id": "ytFY1tjRBByU",
    "outputId": "fce9d3ee-051f-4b09-b5dd-c8a834dc3e22"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:===============>                                       (44 + 45) / 160]\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4G5XozIiQTEx"
   },
   "source": [
    "### 3. Preview the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-23T02:16:02.607225Z",
     "iopub.status.busy": "2024-06-23T02:16:02.606020Z",
     "iopub.status.idle": "2024-06-23T02:16:03.974056Z",
     "shell.execute_reply": "2024-06-23T02:16:03.972854Z",
     "shell.execute_reply.started": "2024-06-23T02:16:02.607176Z"
    },
    "id": "r86OcjwLv0EU",
    "outputId": "908b16c6-118c-4870-fef3-2dc4086a5ab1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "650028"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of observations\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T02:16:03.976929Z",
     "iopub.status.busy": "2024-06-23T02:16:03.975503Z",
     "iopub.status.idle": "2024-06-23T02:16:06.839263Z",
     "shell.execute_reply": "2024-06-23T02:16:06.838114Z",
     "shell.execute_reply.started": "2024-06-23T02:16:03.976883Z"
    },
    "id": "sfy_ivN4BByV",
    "outputId": "047c2814-4f8d-4015-b1bd-ab3e4a3758c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+\n",
      "|category_label|description_filtered|\n",
      "+--------------+--------------------+\n",
      "|           9.0|9 dead c one hund...|\n",
      "|          11.0|devos endure vill...|\n",
      "|           6.0|college hitch tip...|\n",
      "|          11.0|jonathan kozol de...|\n",
      "|           6.0|reward help kid g...|\n",
      "|           4.0|donald trump say ...|\n",
      "|           7.0|universal orlando...|\n",
      "|           4.0|north carolina bo...|\n",
      "|           4.0|bernie sander hit...|\n",
      "|           6.0|decade way failin...|\n",
      "|           8.0|workmanship war r...|\n",
      "|           7.0|ten strange attra...|\n",
      "|          11.0|bridge divide uph...|\n",
      "|           8.0|kathleen hanna re...|\n",
      "|           4.0|dennis hastert ca...|\n",
      "|           1.0|worker dy minneso...|\n",
      "|           0.0|staterun lender c...|\n",
      "|           3.0|normality l repor...|\n",
      "|           5.0|nintendo q1 profi...|\n",
      "|           0.0|association provi...|\n",
      "+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the dataframe\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T02:16:06.845148Z",
     "iopub.status.busy": "2024-06-23T02:16:06.844639Z",
     "iopub.status.idle": "2024-06-23T02:16:06.855186Z",
     "shell.execute_reply": "2024-06-23T02:16:06.853527Z",
     "shell.execute_reply.started": "2024-06-23T02:16:06.845104Z"
    },
    "id": "awWri7zZQcOl",
    "outputId": "1f969d61-d388-47b3-fd3c-abf38d4a0b92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- category_label: double (nullable = true)\n",
      " |-- description_filtered: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema of the dataframe\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMpXsNNsO_Z6"
   },
   "source": [
    "### 4. Convert filtered descriptions to arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-23T02:16:06.859428Z",
     "iopub.status.busy": "2024-06-23T02:16:06.857848Z",
     "iopub.status.idle": "2024-06-23T02:16:07.352578Z",
     "shell.execute_reply": "2024-06-23T02:16:07.350559Z",
     "shell.execute_reply.started": "2024-06-23T02:16:06.859381Z"
    },
    "id": "Drqnhee0i26r",
    "outputId": "ca8e510c-4855-440f-d3e1-a39f6b13a50d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|category_label|description_filtered                                                                                                                                   |\n",
      "+--------------+-------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|9.0           |[9, dead, c, one, hundred, thirty, military, cargo, carpenter, plane, clangor, georgia]                                                                |\n",
      "|11.0          |[devos, endure, villain, non, student, part, 2]                                                                                                        |\n",
      "|6.0           |[college, hitch, tip, parent]                                                                                                                          |\n",
      "|11.0          |[jonathan, kozol, death, former, long, time, nevertheless, moldiness, read]                                                                            |\n",
      "|6.0           |[reward, help, kid, get, active, dont, necessarily, lead, better, health, study]                                                                       |\n",
      "|4.0           |[donald, trump, say, 70, percent, federal, regulation, go]                                                                                             |\n",
      "|7.0           |[universal, orlando, v, walt, disney, globe, clean, unrivalled]                                                                                        |\n",
      "|4.0           |[north, carolina, board, election, extends, voting, minute, eight, durham, county, precinct]                                                           |\n",
      "|4.0           |[bernie, sander, hit, hillary, clinton, using, racist, term, 1996]                                                                                     |\n",
      "|6.0           |[decade, way, failing, maturity]                                                                                                                       |\n",
      "|8.0           |[workmanship, war, recap, time, year, 1, installment, 4, tooth, fairy, box, gnome, home, angstrom, diy, photo, cubicle, video, recording, poll, parrot]|\n",
      "|7.0           |[ten, strange, attraction, paris, pic]                                                                                                                 |\n",
      "|11.0          |[bridge, divide, uphill, ascent, faculty, diversity]                                                                                                   |\n",
      "|8.0           |[kathleen, hanna, really, doesnt, want, 90, legging, come, back]                                                                                       |\n",
      "|4.0           |[dennis, hastert, case, renews, call, change, child, sex, abuse, reporting, law]                                                                       |\n",
      "|1.0           |[worker, dy, minnesota, viking, stadium, construction, site]                                                                                           |\n",
      "|0.0           |[staterun, lender, corporation, bank, said, recruit, 1200, people, fiscal, aim, achieve, target, adding, 200]                                          |\n",
      "|3.0           |[normality, l, report, modern, covid, 19, case, connect, responsibility, tv, series, worker]                                                           |\n",
      "|5.0           |[nintendo, q1, profit, skyrocket, 541, 989, million, forecast, unchanged]                                                                              |\n",
      "|0.0           |[association, provide, bank, customer, access, insurer, portfolio, make, insurance, accessible]                                                        |\n",
      "+--------------+-------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame with description_filtered as arrays\n",
    "df= df.withColumn('description_filtered', split(col('description_filtered'), ' '))\n",
    "# Show the new DataFrame\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RmBazOpQqXF"
   },
   "source": [
    "## IV- Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cV9aikKbYQzj"
   },
   "source": [
    "We are going word embedding to represent our filtered description.\n",
    "\n",
    "We will try some values of vector size(100, 200, 300, ...) in order to find the optimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74T1zTMRxKP8"
   },
   "source": [
    "## V- Models set up, training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmY4gqj5Q2w_"
   },
   "source": [
    "### 1. Set up Logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T04:02:55.387206Z",
     "iopub.status.busy": "2024-06-23T04:02:55.386745Z",
     "iopub.status.idle": "2024-06-23T04:02:55.405817Z",
     "shell.execute_reply": "2024-06-23T04:02:55.404556Z",
     "shell.execute_reply.started": "2024-06-23T04:02:55.387170Z"
    },
    "id": "f8ya3gJ_PxLc"
   },
   "outputs": [],
   "source": [
    "# Define Logistic Regression classifier\n",
    "lr = LogisticRegression(labelCol=\"category_label\", featuresCol=\"word_embeddings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XT81OlVr5Ck1"
   },
   "source": [
    "### 2. Cross validation\n",
    "\n",
    "3-Fold Cross-validation  without grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T04:35:44.270255Z",
     "iopub.status.busy": "2024-06-23T04:35:44.269495Z",
     "iopub.status.idle": "2024-06-23T04:35:44.293565Z",
     "shell.execute_reply": "2024-06-23T04:35:44.292106Z",
     "shell.execute_reply.started": "2024-06-23T04:35:44.270211Z"
    },
    "id": "LArI4unEDer1",
    "outputId": "6f6463cd-c0bc-485f-989b-5e283447b79d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define parameter grids (you can specify more parameters if needed)\n",
    "paramGrid_lr = ParamGridBuilder().build()\n",
    "# Create cross validators\n",
    "\n",
    "# Cross-validation for Logistic Regression\n",
    "cv_lr = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid_lr,\n",
    "                       evaluator=MulticlassClassificationEvaluator(labelCol=\"category_label\", predictionCol=\"prediction\", metricName=\"accuracy\"),\n",
    "                       numFolds=3, parallelism=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UD0gwMNf7yY7"
   },
   "source": [
    "### 3. Split the data\n",
    "\n",
    "Let us split the data into train and test set: 80% for train and 20% for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T04:35:50.826011Z",
     "iopub.status.busy": "2024-06-23T04:35:50.825498Z",
     "iopub.status.idle": "2024-06-23T04:35:50.841691Z",
     "shell.execute_reply": "2024-06-23T04:35:50.840197Z",
     "shell.execute_reply.started": "2024-06-23T04:35:50.825973Z"
    },
    "id": "pThnAKRy8LqP"
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "(train_set, test_set) = df.randomSplit([0.80, 0.20], seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M84xeE8i67YF"
   },
   "source": [
    "### 4. Create a function for model training\n",
    "\n",
    "Let us create a function which takes as argument a model that it trains and then returns the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T04:35:52.303808Z",
     "iopub.status.busy": "2024-06-23T04:35:52.302859Z",
     "iopub.status.idle": "2024-06-23T04:35:52.308992Z",
     "shell.execute_reply": "2024-06-23T04:35:52.307709Z",
     "shell.execute_reply.started": "2024-06-23T04:35:52.303765Z"
    },
    "id": "AvRF-E1-7ncY"
   },
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    return model.fit(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-fBEB1f9aRD"
   },
   "source": [
    "### 5. Define the evaluator and a function to evaluate the model\n",
    "\n",
    "The function takes as parameter a fitted model, evaluates the model on train and test split and then return the train and test performance. The accuracy is the metric used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator=MulticlassClassificationEvaluator(labelCol=\"category_label\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T04:35:54.695407Z",
     "iopub.status.busy": "2024-06-23T04:35:54.694969Z",
     "iopub.status.idle": "2024-06-23T04:35:54.709092Z",
     "shell.execute_reply": "2024-06-23T04:35:54.707682Z",
     "shell.execute_reply.started": "2024-06-23T04:35:54.695371Z"
    },
    "id": "dIKVzBw1BByY",
    "outputId": "5d3fad3a-398a-4b1e-e558-91225f370d16"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Function to evaluate model and get best parameters\n",
    "def evaluate_model(fitted_model):\n",
    "\n",
    "    print('Making predictions on the training set')\n",
    "\n",
    "    train_predictions = fitted_model.transform(train_set)\n",
    "\n",
    "    print('Making predictions on the test set')\n",
    "    test_predictions = fitted_model.transform(test_set)\n",
    "\n",
    "    print('Evaluating the model on training set')\n",
    "    train_accuracy = evaluator.evaluate(train_predictions)\n",
    "\n",
    "    print('Evaluating the model on test set')\n",
    "    test_accuracy = evaluator.evaluate(test_predictions)\n",
    "\n",
    "    print('Train accuracy:',train_accuracy)\n",
    "    print('Test accuracy:',test_accuracy)\n",
    "    return train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline_dbcb36ef3008"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pipelines\n",
    "\n",
    "# Define the HashingTF and IDF stages\n",
    "# Define Word2Vec\n",
    "\n",
    "word2Vec = Word2Vec(vectorSize=100, minCount=5, inputCol=\"description_filtered\", outputCol=\"word_embeddings\")\n",
    "\n",
    "# Pipeline for Logistic Regression\n",
    "pipeline_lr = Pipeline(stages=[word2Vec, cv_lr])\n",
    "pipeline_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yG6dMBjzLXWA"
   },
   "source": [
    "### 6. Create a function which takes pipelines and train the models, evaluate them and then return the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T04:35:59.398018Z",
     "iopub.status.busy": "2024-06-23T04:35:59.397536Z",
     "iopub.status.idle": "2024-06-23T04:35:59.407265Z",
     "shell.execute_reply": "2024-06-23T04:35:59.405932Z",
     "shell.execute_reply.started": "2024-06-23T04:35:59.397979Z"
    },
    "id": "8MmY_Fp54MXb"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model_pipeline,model_name=\"Logistic Regression\"):\n",
    "    \n",
    "    print(f\"Training {model_name} model\")\n",
    "\n",
    "    # Fit the model pipeline to the training set\n",
    "    #fitted_model = model_pipeline.fit(train_set)\n",
    "    fitted_model = train_model(model_pipeline)\n",
    "\n",
    "    print(\"Done\")\n",
    "    print(f\"Evaluating {model_name} model\")\n",
    "\n",
    "    # Evaluate the fitted model\n",
    "    train_accuracy, test_accuracy = evaluate_model(fitted_model)\n",
    "    print(\"Done\")\n",
    "    # Store the results\n",
    "    results= {\n",
    "            'model_name': model_name,\n",
    "            'fitted_model': fitted_model,\n",
    "            \"train_accuracy\": train_accuracy,\n",
    "            \"test_accuracy\": test_accuracy\n",
    "        }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYDcrjUHBQHf"
   },
   "source": [
    "### 5. Call the function and interpret the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WyuTd4ijV1E"
   },
   "source": [
    "#### a. Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T04:36:01.108574Z",
     "iopub.status.busy": "2024-06-23T04:36:01.108166Z",
     "iopub.status.idle": "2024-06-23T05:03:14.902112Z",
     "shell.execute_reply": "2024-06-23T05:03:14.900726Z",
     "shell.execute_reply.started": "2024-06-23T04:36:01.108542Z"
    },
    "id": "9T4JAj-QId2e",
    "outputId": "b7423773-bf83-489f-b21a-2fea8b04e7ad",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 160]]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Evaluating Logistic Regression model\n",
      "Making predictions on the training set\n",
      "Making predictions on the test set\n",
      "Evaluating the model on training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model on test set\n",
      "Train accuracy: 0.67924459331285\n",
      "Test accuracy: 0.6786917968600054\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'Logistic Regression',\n",
       " 'fitted_model': PipelineModel_14c3f5949044,\n",
       " 'train_accuracy': 0.67924459331285,\n",
       " 'test_accuracy': 0.6786917968600054}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = train_and_evaluate_model(pipeline_lr)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                160]]]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Evaluating Logistic Regression model\n",
      "Making predictions on the training set\n",
      "Making predictions on the test set\n",
      "Evaluating the model on training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model on test set\n",
      "Train accuracy: 0.694435840261037\n",
      "Test accuracy: 0.6936854631300142\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'Logistic Regression',\n",
       " 'fitted_model': PipelineModel_11f8cf869f6a,\n",
       " 'train_accuracy': 0.694435840261037,\n",
       " 'test_accuracy': 0.6936854631300142}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pipelines\n",
    "\n",
    "# Define the HashingTF and IDF stages\n",
    "# Define Word2Vec\n",
    "\n",
    "word2Vec = Word2Vec(vectorSize=200, minCount=5, inputCol=\"description_filtered\", outputCol=\"word_embeddings\")\n",
    "\n",
    "# Pipeline for Logistic Regression\n",
    "pipeline_lr = Pipeline(stages=[word2Vec, cv_lr])\n",
    "pipeline_lr\n",
    "results = train_and_evaluate_model(pipeline_lr)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                0) / 160]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Evaluating Logistic Regression model\n",
      "Making predictions on the training set\n",
      "Making predictions on the test set\n",
      "Evaluating the model on training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model on test set\n",
      "Train accuracy: 0.7014773757005462\n",
      "Test accuracy: 0.7003262830601512\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'Logistic Regression',\n",
       " 'fitted_model': PipelineModel_f40dc6bf3e23,\n",
       " 'train_accuracy': 0.7014773757005462,\n",
       " 'test_accuracy': 0.7003262830601512}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pipelines\n",
    "\n",
    "# Define the HashingTF and IDF stages\n",
    "# Define Word2Vec\n",
    "\n",
    "word2Vec = Word2Vec(vectorSize=300, minCount=5, inputCol=\"description_filtered\", outputCol=\"word_embeddings\")\n",
    "\n",
    "# Pipeline for Logistic Regression\n",
    "pipeline_lr = Pipeline(stages=[word2Vec, cv_lr])\n",
    "pipeline_lr\n",
    "results = train_and_evaluate_model(pipeline_lr)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                ) / 160]]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Evaluating Logistic Regression model\n",
      "Making predictions on the training set\n",
      "Making predictions on the test set\n",
      "Evaluating the model on training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model on test set\n",
      "Train accuracy: 0.7032916292304525\n",
      "Test accuracy: 0.7014701930827991\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'Logistic Regression',\n",
       " 'fitted_model': PipelineModel_416b8c8d6d14,\n",
       " 'train_accuracy': 0.7032916292304525,\n",
       " 'test_accuracy': 0.7014701930827991}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pipelines\n",
    "\n",
    "# Define the HashingTF and IDF stages\n",
    "# Define Word2Vec\n",
    "\n",
    "word2Vec = Word2Vec(vectorSize=400, minCount=5, inputCol=\"description_filtered\", outputCol=\"word_embeddings\")\n",
    "\n",
    "# Pipeline for Logistic Regression\n",
    "pipeline_lr = Pipeline(stages=[word2Vec, cv_lr])\n",
    "pipeline_lr\n",
    "results = train_and_evaluate_model(pipeline_lr)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqVehK6LjV1F"
   },
   "source": [
    "#### b. Results interpretetion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T04:30:08.055776Z",
     "iopub.status.busy": "2024-06-23T04:30:08.055400Z",
     "iopub.status.idle": "2024-06-23T04:30:08.063026Z",
     "shell.execute_reply": "2024-06-23T04:30:08.061704Z",
     "shell.execute_reply.started": "2024-06-23T04:30:08.055745Z"
    },
    "id": "ycLhdvlMJ8nB",
    "outputId": "dc85984c-0c54-44a3-e2c1-3c9b26ffcf5f"
   },
   "source": [
    "After trying with vector size in [100,200,300,400] we remark that the performance of the model doesn't increase significantly anymore. Wee then conclude that 300 is the optimum value for the vector size.\n",
    "\n",
    "The performance for vecsize=300 is 70%. We will use that value of vecsize for the following, to tune hyperparameters so as to enhance the performance of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xkME6ByNOegG"
   },
   "source": [
    "## VI- Logistic regression hyperparameters tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADKEJXPm1-cu"
   },
   "source": [
    "Let us use Grid search with cross validation to find the best regularisation parameter. We will use 10 values of regularisation parameter varing in a log scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAWi0NqwSzgp"
   },
   "source": [
    "### 1. Pipeline creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T07:46:24.808926Z",
     "iopub.status.busy": "2024-06-23T07:46:24.808374Z",
     "iopub.status.idle": "2024-06-23T07:46:24.847895Z",
     "shell.execute_reply": "2024-06-23T07:46:24.846761Z",
     "shell.execute_reply.started": "2024-06-23T07:46:24.808885Z"
    },
    "id": "Wtq5K0JbOdpD",
    "outputId": "00a6afd5-4bf2-4ff2-edea-9f1c976d24fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline_8b37f1944bc9"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create pipelines\n",
    "\n",
    "# Define the HashingTF and IDF stages\n",
    "# Define Word2Vec\n",
    "\n",
    "word2Vec = Word2Vec(vectorSize=300, minCount=5, inputCol=\"description_filtered\", outputCol=\"word_embeddings\")\n",
    "\n",
    "\n",
    "\n",
    "# Define parameter grids for Logistic Regression with ElasticNet\n",
    "reg_values = np.logspace(-4, 4, num=50)\n",
    "\n",
    "paramGrid_lr = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, reg_values) \\\n",
    "    .build()\n",
    "#\n",
    "\n",
    "# Create Cross-validation for Logistic Regression\n",
    "cv_lr = CrossValidator(estimator=lr, estimatorParamMaps=paramGrid_lr,\n",
    "                       evaluator=evaluator,\n",
    "                       numFolds=3, parallelism=3)\n",
    "\n",
    "# Create pipeline for Logistic Regression\n",
    "pipeline_lr = Pipeline(stages=[word2Vec, cv_lr])\n",
    "\n",
    "pipeline_lr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XhMJxEzS87h"
   },
   "source": [
    "### 2. Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T07:46:32.358850Z",
     "iopub.status.busy": "2024-06-23T07:46:32.358308Z"
    },
    "id": "4bSLe3K5TL1L",
    "outputId": "e7b40f35-1256-4155-b442-dd5adc8a8be0",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                ) / 160]]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Evaluating Logistic Regression model\n",
      "Making predictions on the training set\n",
      "Making predictions on the test set\n",
      "Evaluating the model on training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model on test set\n",
      "Train accuracy: 0.7014773757005462\n",
      "Test accuracy: 0.7003262830601512\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model_name': 'Logistic Regression',\n",
       " 'fitted_model': PipelineModel_2706c8daf1d0,\n",
       " 'train_accuracy': 0.7014773757005462,\n",
       " 'test_accuracy': 0.7003262830601512}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = train_and_evaluate_model(pipeline_lr)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vJUT2CTjV1G"
   },
   "source": [
    "### 3. Interpreting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T05:04:54.742560Z",
     "iopub.status.busy": "2024-06-23T05:04:54.741716Z",
     "iopub.status.idle": "2024-06-23T05:04:54.750051Z",
     "shell.execute_reply": "2024-06-23T05:04:54.748907Z",
     "shell.execute_reply.started": "2024-06-23T05:04:54.742519Z"
    },
    "id": "nwTW61WLjV1G",
    "outputId": "b23c12a6-0de2-4551-c411-5f38d9d60a60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'Logistic Regression',\n",
       " 'fitted_model': PipelineModel_2706c8daf1d0,\n",
       " 'train_accuracy': 0.7014773757005462,\n",
       " 'test_accuracy': 0.7003262830601512}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4dR1ws92gZ6"
   },
   "source": [
    "Despite extensive hyperparameter tuning, the accuracy of the Logistic Regression model remains around 70% for both the training and test sets. This consistency indicates good generalization but suggests that the current approach has reached its performance limit. Further improvements may require additional feature engineering or exploring more complex models.\n",
    "\n",
    "We will save our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yUlLvsWVTkDy"
   },
   "source": [
    "### 4. Get the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "k5rCb_boTk3e",
    "outputId": "055e3d04-ebe4-42e7-b42f-5f2e2a2bb4db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for Logistic regression:\n",
      "  aggregationDepth: 2\n",
      "  elasticNetParam: 0.0\n",
      "  family: auto\n",
      "  featuresCol: word_embeddings\n",
      "  fitIntercept: True\n",
      "  labelCol: category_label\n",
      "  maxBlockSizeInMB: 0.0\n",
      "  maxIter: 100\n",
      "  predictionCol: prediction\n",
      "  probabilityCol: probability\n",
      "  rawPredictionCol: rawPrediction\n",
      "  regParam: 9.999999999999999e-05\n",
      "  standardization: True\n",
      "  threshold: 0.5\n",
      "  tol: 1e-06\n"
     ]
    }
   ],
   "source": [
    "fitted_model=results['fitted_model']\n",
    "\n",
    "# Get the best model\n",
    "best_model = fitted_model.stages[-1].bestModel\n",
    "\n",
    "# Print the best parameters\n",
    "print(f\"Best parameters for Logistic regression:\")\n",
    "\n",
    "for param, value in best_model.extractParamMap().items():\n",
    "     print(f\"  {param.name}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uEH0OfIqUxOg"
   },
   "source": [
    "### 5. Save the best model\n",
    "\n",
    "Now let us save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/29 02:27:59 WARN TaskSetManager: Stage 142942 contains a task of very large size (1091 KiB). The maximum recommended task size is 1000 KiB.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# With pipeline\n",
    "fitted_model.save(\"pipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "xX4pmvAVBByZ",
    "outputId": "843aa553-e419-43ba-dbb3-3ebb1a67f454"
   },
   "outputs": [],
   "source": [
    "best_model.save(\"simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnFsw8x5Vyy2"
   },
   "source": [
    "## VII- Summary\n",
    "\n",
    "In this notebook we have studied  **Logistic regression** with word embedding.\n",
    "\n",
    "Our study reveals that our model, even after tunning can not outperforms 70%.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "NSyD5awwBByb",
    "outputId": "53219ebe-67ca-4b28-a0b7-1d6d7554d132"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[category_label: double, description_filtered: array<string>]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the cache\n",
    "df.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "FbaTgrZajV1H"
   },
   "outputs": [],
   "source": [
    "# Stop the spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5264351,
     "sourceId": 8761933,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30732,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "lr_env",
   "language": "python",
   "name": "lr_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
