{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u-qFVy2lBaqu"
   },
   "source": [
    "# News categorization\n",
    "\n",
    "In this notebook we are going to build a Machine Learning model for news categorisation.\n",
    "\n",
    "Our dataset is the one we preprocessed before, which has two colums:\n",
    "\n",
    "- **description_filtered** which is the filtered descrition after performing cleaning, tokenisation, lemmatization and stopword removal on the description of the news\n",
    "- **category_label** which is a numeric value that represents the category of our label.\n",
    "\n",
    "We converted the dataset format from csv to parket.\n",
    "\n",
    "We are going to study two classification models: **Random Forest**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNfMRWDbFXDJ"
   },
   "source": [
    "## I- Modules import\n",
    "\n",
    "Let us import the modules we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T01:34:37.940430Z",
     "iopub.status.busy": "2024-06-23T01:34:37.940089Z",
     "iopub.status.idle": "2024-06-23T01:34:38.344466Z",
     "shell.execute_reply": "2024-06-23T01:34:38.343497Z",
     "shell.execute_reply.started": "2024-06-23T01:34:37.940390Z"
    },
    "id": "3QYNQcr-FQLs",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.feature import  IDF, HashingTF\n",
    "from pyspark.ml import  Pipeline\n",
    "from math import ceil,log2\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.sql.functions import col,explode,split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nj7Qu-EvK9_Y"
   },
   "source": [
    "## II- Spark context and session creation\n",
    "\n",
    "Let us create a spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T01:34:38.346238Z",
     "iopub.status.busy": "2024-06-23T01:34:38.345951Z",
     "iopub.status.idle": "2024-06-23T01:34:46.284574Z",
     "shell.execute_reply": "2024-06-23T01:34:46.283369Z",
     "shell.execute_reply.started": "2024-06-23T01:34:38.346202Z"
    },
    "id": "aFZWn6-QBByS",
    "outputId": "b7430067-1724-411c-c9fb-aa0e1cf8140e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/06/29 18:40:06 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://node10.cm.cluster:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>NewsCategorization</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fffc16f86d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = (SparkSession.builder\n",
    "    .master('local[*]')\n",
    "    .appName(\"NewsCategorization\")\n",
    "   .config(\"spark.driver.memory\", '320g')\\\n",
    "    .config(\"spark.driver.memoryOverhead\", \"1t\")\n",
    "    .getOrCreate()\n",
    "        )\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuV9CWoMN60A"
   },
   "source": [
    "## III- Dataframe preparing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Em4ZWvqhPoHt"
   },
   "source": [
    "### 1. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T01:39:10.486501Z",
     "iopub.status.busy": "2024-06-23T01:39:10.486106Z",
     "iopub.status.idle": "2024-06-23T01:39:10.684396Z",
     "shell.execute_reply": "2024-06-23T01:39:10.683175Z",
     "shell.execute_reply.started": "2024-06-23T01:39:10.486467Z"
    },
    "id": "xMI_45McvZto",
    "outputId": "7b2ef733-bdeb-4756-b088-efe035e50be6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Load the ata\n",
    "\n",
    "df = spark.read.parquet(\"rf/input/news.parquet\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x4csdl2FOVf8"
   },
   "source": [
    "### 2. Partition and cache the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T01:39:11.919506Z",
     "iopub.status.busy": "2024-06-23T01:39:11.919139Z",
     "iopub.status.idle": "2024-06-23T01:39:11.995334Z",
     "shell.execute_reply": "2024-06-23T01:39:11.994328Z",
     "shell.execute_reply.started": "2024-06-23T01:39:11.919468Z"
    },
    "id": "4EXrJ3GIBByT",
    "outputId": "ddd03fd8-a9c6-436c-abe7-a1828a821abe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the current numbe rof RDD partitions\n",
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T01:39:12.224180Z",
     "iopub.status.busy": "2024-06-23T01:39:12.223843Z",
     "iopub.status.idle": "2024-06-23T01:39:12.228512Z",
     "shell.execute_reply": "2024-06-23T01:39:12.227320Z",
     "shell.execute_reply.started": "2024-06-23T01:39:12.224144Z"
    },
    "id": "PPBefKKqBByU"
   },
   "outputs": [],
   "source": [
    "# Repartitionning: Use 4 partitions per core\n",
    "num_partitions=4*42\n",
    "df= df.repartition(num_partitions).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T01:39:12.449834Z",
     "iopub.status.busy": "2024-06-23T01:39:12.449470Z",
     "iopub.status.idle": "2024-06-23T01:39:12.458510Z",
     "shell.execute_reply": "2024-06-23T01:39:12.457362Z",
     "shell.execute_reply.started": "2024-06-23T01:39:12.449774Z"
    },
    "id": "ytFY1tjRBByU",
    "outputId": "fce9d3ee-051f-4b09-b5dd-c8a834dc3e22"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:==============================================>       (145 + 23) / 168]\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "168"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4G5XozIiQTEx"
   },
   "source": [
    "### 3. Preview the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-23T01:39:12.990148Z",
     "iopub.status.busy": "2024-06-23T01:39:12.989769Z",
     "iopub.status.idle": "2024-06-23T01:39:14.198111Z",
     "shell.execute_reply": "2024-06-23T01:39:14.197180Z",
     "shell.execute_reply.started": "2024-06-23T01:39:12.990107Z"
    },
    "id": "r86OcjwLv0EU",
    "outputId": "908b16c6-118c-4870-fef3-2dc4086a5ab1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "650028"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of observations\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T01:39:14.204566Z",
     "iopub.status.busy": "2024-06-23T01:39:14.203865Z",
     "iopub.status.idle": "2024-06-23T01:39:15.303323Z",
     "shell.execute_reply": "2024-06-23T01:39:15.302453Z",
     "shell.execute_reply.started": "2024-06-23T01:39:14.204514Z"
    },
    "id": "sfy_ivN4BByV",
    "outputId": "047c2814-4f8d-4015-b1bd-ab3e4a3758c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+\n",
      "|category_label|description_filtered|\n",
      "+--------------+--------------------+\n",
      "|          10.0|vatican palace sa...|\n",
      "|          10.0|u mho secular com...|\n",
      "|           1.0|ciara kelly tampo...|\n",
      "|           0.0|vepa kamesam 8217...|\n",
      "|           6.0|reward help kid g...|\n",
      "|           7.0|inside city light...|\n",
      "|           4.0|hillary clinton t...|\n",
      "|          11.0|new return new yo...|\n",
      "|           6.0|parent ask google...|\n",
      "|           5.0|fortnite entropy ...|\n",
      "|           7.0|discovery channel...|\n",
      "|           2.0|homegrown stem ac...|\n",
      "|           5.0|fact checking hil...|\n",
      "|           6.0|dad show incredib...|\n",
      "|           9.0|savanna georgia w...|\n",
      "|           1.0|six bristol city ...|\n",
      "|           2.0|      red admiral 20|\n",
      "|           6.0| proposal antarctica|\n",
      "|          10.0|troubled anna mar...|\n",
      "|           1.0|kanye west make s...|\n",
      "+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the dataframe\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T01:39:15.304856Z",
     "iopub.status.busy": "2024-06-23T01:39:15.304538Z",
     "iopub.status.idle": "2024-06-23T01:39:15.313684Z",
     "shell.execute_reply": "2024-06-23T01:39:15.312700Z",
     "shell.execute_reply.started": "2024-06-23T01:39:15.304815Z"
    },
    "id": "awWri7zZQcOl",
    "outputId": "1f969d61-d388-47b3-fd3c-abf38d4a0b92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- category_label: double (nullable = true)\n",
      " |-- description_filtered: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema of the dataframe\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VMpXsNNsO_Z6"
   },
   "source": [
    "### 4. Convert filtered descriptions to arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-06-23T01:39:15.317313Z",
     "iopub.status.busy": "2024-06-23T01:39:15.315782Z",
     "iopub.status.idle": "2024-06-23T01:39:15.780316Z",
     "shell.execute_reply": "2024-06-23T01:39:15.779361Z",
     "shell.execute_reply.started": "2024-06-23T01:39:15.317224Z"
    },
    "id": "Drqnhee0i26r",
    "outputId": "ca8e510c-4855-440f-d3e1-a39f6b13a50d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------------------------------------------------------------------------------------------------+\n",
      "|category_label|description_filtered                                                                                     |\n",
      "+--------------+---------------------------------------------------------------------------------------------------------+\n",
      "|10.0          |[vatican, palace, say, transgender, valet, de, chambre, become, godparent]                               |\n",
      "|10.0          |[u, mho, secular, community, won, significant, legal, victory]                                           |\n",
      "|1.0           |[ciara, kelly, tampon, ad, protest, hundred, box, received, already]                                     |\n",
      "|0.0           |[vepa, kamesam, 8217s, term, rbi, extended, three, month]                                                |\n",
      "|6.0           |[reward, help, kid, get, active, dont, necessarily, lead, better, health, study]                         |\n",
      "|7.0           |[inside, city, light, urban, explorer]                                                                   |\n",
      "|4.0           |[hillary, clinton, tell, story, young, woman, moved, obama, heroin, epidemic]                            |\n",
      "|11.0          |[new, return, new, york, city, mayor, decides, schooltime, renewal, plan, failed, still, claim, achiever]|\n",
      "|6.0           |[parent, ask, google, son, genius, daughter, fatness]                                                    |\n",
      "|5.0           |[fortnite, entropy, volt, buck, today, permanently, bit, bum]                                            |\n",
      "|7.0           |[discovery, channel, hawaii, show, amazing, island]                                                      |\n",
      "|2.0           |[homegrown, stem, accounted, 14, 865m, worth, flower, sold, britain, last, year]                         |\n",
      "|5.0           |[fact, checking, hilary, clinton, trump, non, decent]                                                    |\n",
      "|6.0           |[dad, show, incredible, patience, face, incessant, kid, enquiry]                                         |\n",
      "|9.0           |[savanna, georgia, warehouse, fire, burn, fivesome, 600, ton, golosh]                                    |\n",
      "|1.0           |[six, bristol, city, player, benefit, dean, holdens, appointment]                                        |\n",
      "|2.0           |[red, admiral, 20]                                                                                       |\n",
      "|6.0           |[proposal, antarctica]                                                                                   |\n",
      "|10.0          |[troubled, anna, mary, robertson, moses, operating, theater, traumatic, descent, book]                   |\n",
      "|1.0           |[kanye, west, make, surprise, appearance, odd, future, carnival]                                         |\n",
      "+--------------+---------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame with description_filtered as arrays\n",
    "df= df.withColumn('description_filtered', split(col('description_filtered'), ' '))\n",
    "# Show the new DataFrame\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RmBazOpQqXF"
   },
   "source": [
    "## IV- Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LjsTG0YLSyEn"
   },
   "source": [
    "### 1. Explode the filtered descriptions to get the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T01:39:17.002312Z",
     "iopub.status.busy": "2024-06-23T01:39:17.001412Z",
     "iopub.status.idle": "2024-06-23T01:39:17.657638Z",
     "shell.execute_reply": "2024-06-23T01:39:17.656616Z",
     "shell.execute_reply.started": "2024-06-23T01:39:17.002244Z"
    },
    "id": "4qON2vCKBByX",
    "outputId": "eb455478-f7bd-47ba-b4f4-d56d323886d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|        col|\n",
      "+-----------+\n",
      "|    vatican|\n",
      "|     palace|\n",
      "|        say|\n",
      "|transgender|\n",
      "|      valet|\n",
      "|         de|\n",
      "|    chambre|\n",
      "|     become|\n",
      "|  godparent|\n",
      "|          u|\n",
      "|        mho|\n",
      "|    secular|\n",
      "|  community|\n",
      "|        won|\n",
      "|significant|\n",
      "|      legal|\n",
      "|    victory|\n",
      "|      ciara|\n",
      "|      kelly|\n",
      "|     tampon|\n",
      "+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exploded_df=df.select(explode(df.description_filtered)).alias('words')\n",
    "exploded_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MohTRQirTXD3"
   },
   "source": [
    "### 2. Get unique words in the filtered_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T01:39:18.014050Z",
     "iopub.status.busy": "2024-06-23T01:39:18.013740Z",
     "iopub.status.idle": "2024-06-23T01:39:18.026795Z",
     "shell.execute_reply": "2024-06-23T01:39:18.025677Z",
     "shell.execute_reply.started": "2024-06-23T01:39:18.014020Z"
    },
    "id": "2NbJFyQlBByX"
   },
   "outputs": [],
   "source": [
    "unique_words=exploded_df.distinct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t-UjxthKU0Rq"
   },
   "source": [
    "### 3. Cache and show the unique words dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T01:39:20.229144Z",
     "iopub.status.busy": "2024-06-23T01:39:20.228102Z",
     "iopub.status.idle": "2024-06-23T01:39:25.901406Z",
     "shell.execute_reply": "2024-06-23T01:39:25.900143Z",
     "shell.execute_reply.started": "2024-06-23T01:39:20.229084Z"
    },
    "id": "h1S8h39xBByX",
    "outputId": "381e204f-78f7-41a2-e511-7a40f64b3caf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 16:====================================================> (164 + 4) / 168]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|          col|\n",
      "+-------------+\n",
      "|    godparent|\n",
      "|        still|\n",
      "|       travel|\n",
      "|         hope|\n",
      "|       voyage|\n",
      "|intermarriage|\n",
      "|infinitesimal|\n",
      "|       online|\n",
      "|     mushball|\n",
      "| transference|\n",
      "|       harder|\n",
      "|          art|\n",
      "|       outfit|\n",
      "|        spoil|\n",
      "|       biting|\n",
      "|     cautious|\n",
      "|      elevate|\n",
      "|     incoming|\n",
      "|       poetry|\n",
      "|   hoverboard|\n",
      "+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "unique_words=unique_words.cache()\n",
    "unique_words.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCb1pLl3VLOL"
   },
   "source": [
    "### 4. Get the vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T01:39:25.903881Z",
     "iopub.status.busy": "2024-06-23T01:39:25.903546Z",
     "iopub.status.idle": "2024-06-23T01:39:29.487395Z",
     "shell.execute_reply": "2024-06-23T01:39:29.486276Z",
     "shell.execute_reply.started": "2024-06-23T01:39:25.903839Z"
    },
    "id": "dCakXZ3PBByX",
    "outputId": "c391ee19-f5c6-4a9e-cc53-4c4cd0b031e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114967"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size=unique_words.count()\n",
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ycUp4mQDVbZ1"
   },
   "source": [
    "### 5. Unpersit the unique words dataframe(not needed anymore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T01:39:29.489935Z",
     "iopub.status.busy": "2024-06-23T01:39:29.489536Z",
     "iopub.status.idle": "2024-06-23T01:39:29.523066Z",
     "shell.execute_reply": "2024-06-23T01:39:29.522048Z",
     "shell.execute_reply.started": "2024-06-23T01:39:29.489882Z"
    },
    "id": "nS-8eBNnBByX"
   },
   "outputs": [],
   "source": [
    "unique_words=unique_words.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irYncNP3WWhr"
   },
   "source": [
    "### 6. Get the smallest `n` such that $2^n$ is greater than `vocabulary_size`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T01:39:29.525327Z",
     "iopub.status.busy": "2024-06-23T01:39:29.525010Z",
     "iopub.status.idle": "2024-06-23T01:39:29.533932Z",
     "shell.execute_reply": "2024-06-23T01:39:29.532997Z",
     "shell.execute_reply.started": "2024-06-23T01:39:29.525286Z"
    },
    "id": "H0nzNFsoBByY",
    "outputId": "83b3aebf-db97-48f0-df3e-46aa7c20ea0b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n=ceil(log2(vocabulary_size))\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtwfZn61Yzh-"
   },
   "source": [
    "### 7. Get the number of features for HashingTF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T01:39:29.537115Z",
     "iopub.status.busy": "2024-06-23T01:39:29.536240Z",
     "iopub.status.idle": "2024-06-23T01:39:29.559447Z",
     "shell.execute_reply": "2024-06-23T01:39:29.554899Z",
     "shell.execute_reply.started": "2024-06-23T01:39:29.537066Z"
    },
    "id": "FviyZsE_YxxT",
    "outputId": "57e3860d-eecc-4303-ae30-f6913a76d40b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features=2**n\n",
    "num_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cV9aikKbYQzj"
   },
   "source": [
    "### 8. Define the HashingTF and IDF stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T01:39:29.562713Z",
     "iopub.status.busy": "2024-06-23T01:39:29.561871Z",
     "iopub.status.idle": "2024-06-23T01:39:29.624106Z",
     "shell.execute_reply": "2024-06-23T01:39:29.622995Z",
     "shell.execute_reply.started": "2024-06-23T01:39:29.562642Z"
    },
    "id": "bIL-PyIHYm4b"
   },
   "outputs": [],
   "source": [
    "# Define the HashingTF and IDF stages\n",
    "hashingTF = HashingTF(inputCol=\"description_filtered\", outputCol=\"rawFeatures\", numFeatures=num_features)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "74T1zTMRxKP8"
   },
   "source": [
    "## V- Models set up, training and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmY4gqj5Q2w_"
   },
   "source": [
    "### 1. Set up Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T01:39:30.855806Z",
     "iopub.status.busy": "2024-06-23T01:39:30.855502Z",
     "iopub.status.idle": "2024-06-23T01:39:30.951465Z",
     "shell.execute_reply": "2024-06-23T01:39:30.950551Z",
     "shell.execute_reply.started": "2024-06-23T01:39:30.855773Z"
    },
    "id": "f8ya3gJ_PxLc"
   },
   "outputs": [],
   "source": [
    "# Define the classifier\n",
    "\n",
    "# Define random forest Tree classifier\n",
    "rf = RandomForestClassifier(labelCol=\"category_label\", featuresCol=\"features\",seed=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XT81OlVr5Ck1"
   },
   "source": [
    "### 2. Set up pipelines\n",
    "\n",
    "We will  set up pipelines of the following transformations for Native Bayes and Linear reggression\n",
    "\n",
    "- HashingTF\n",
    "- IDF\n",
    "- 3-Fold Cross-validation  without grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T01:39:31.382650Z",
     "iopub.status.busy": "2024-06-23T01:39:31.382337Z",
     "iopub.status.idle": "2024-06-23T01:39:31.411770Z",
     "shell.execute_reply": "2024-06-23T01:39:31.410851Z",
     "shell.execute_reply.started": "2024-06-23T01:39:31.382617Z"
    },
    "id": "LArI4unEDer1",
    "outputId": "6f6463cd-c0bc-485f-989b-5e283447b79d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define parameter grids \n",
    "paramGrid_rf = ParamGridBuilder().build()\n",
    "\n",
    "# Cross-validation for Random Forest\n",
    "cv_rf = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid_rf,\n",
    "                       evaluator=MulticlassClassificationEvaluator(labelCol=\"category_label\", predictionCol=\"prediction\", metricName=\"accuracy\"),\n",
    "                       numFolds=3, parallelism=1)\n",
    "\n",
    "# Create pipeline\n",
    "\n",
    "# Pipeline for Random Forest\n",
    "pipeline_rf = Pipeline(stages=[hashingTF, idf, cv_rf])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UD0gwMNf7yY7"
   },
   "source": [
    "### 3. Split the data\n",
    "\n",
    "Let us split the data into train and test set: 80% for train and 20% for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T01:39:32.174587Z",
     "iopub.status.busy": "2024-06-23T01:39:32.174199Z",
     "iopub.status.idle": "2024-06-23T01:39:32.207400Z",
     "shell.execute_reply": "2024-06-23T01:39:32.206343Z",
     "shell.execute_reply.started": "2024-06-23T01:39:32.174548Z"
    },
    "id": "pThnAKRy8LqP"
   },
   "outputs": [],
   "source": [
    "# Split data\n",
    "(train_set, test_set) = df.randomSplit([0.80, 0.20], seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M84xeE8i67YF"
   },
   "source": [
    "### 4. Create a function for model training\n",
    "\n",
    "Let us create a function which takes as argument a model that it trains and then returns the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T01:39:33.140545Z",
     "iopub.status.busy": "2024-06-23T01:39:33.140164Z",
     "iopub.status.idle": "2024-06-23T01:39:33.145418Z",
     "shell.execute_reply": "2024-06-23T01:39:33.144396Z",
     "shell.execute_reply.started": "2024-06-23T01:39:33.140504Z"
    },
    "id": "AvRF-E1-7ncY"
   },
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    return model.fit(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K-fBEB1f9aRD"
   },
   "source": [
    "### 5. Define a function to evaluate the model\n",
    "\n",
    "The function takes as parameter a fitted model, evaluates the model on train and test split and then return the train and test performance. The accuracy is the metric used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T01:39:35.141149Z",
     "iopub.status.busy": "2024-06-23T01:39:35.140839Z",
     "iopub.status.idle": "2024-06-23T01:39:35.155622Z",
     "shell.execute_reply": "2024-06-23T01:39:35.154566Z",
     "shell.execute_reply.started": "2024-06-23T01:39:35.141117Z"
    },
    "id": "dIKVzBw1BByY",
    "outputId": "5d3fad3a-398a-4b1e-e558-91225f370d16"
   },
   "outputs": [],
   "source": [
    "# Initialize the evaluator\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"category_label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "# Function to evaluate model and get best parameters\n",
    "def evaluate_model(fitted_model):\n",
    "\n",
    "    print('Making predictions on the training set')\n",
    "\n",
    "    train_predictions = fitted_model.transform(train_set)\n",
    "\n",
    "    print('Making predictions on the test set')\n",
    "    test_predictions = fitted_model.transform(test_set)\n",
    "\n",
    "    print('Evaluating the model on training set')\n",
    "    train_accuracy = evaluator.evaluate(train_predictions)\n",
    "\n",
    "    print('Evaluating the model on test set')\n",
    "    test_accuracy = evaluator.evaluate(test_predictions)\n",
    "\n",
    "    print('Train accuracy:',train_accuracy)\n",
    "    print('Test accuracy:',test_accuracy)\n",
    "    return train_accuracy, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yG6dMBjzLXWA"
   },
   "source": [
    "### 6. Create a function which takes pipelines and train the models, evaluate them and then return the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T01:39:48.291101Z",
     "iopub.status.busy": "2024-06-23T01:39:48.290773Z",
     "iopub.status.idle": "2024-06-23T01:39:48.300369Z",
     "shell.execute_reply": "2024-06-23T01:39:48.299348Z",
     "shell.execute_reply.started": "2024-06-23T01:39:48.291060Z"
    },
    "id": "8MmY_Fp54MXb"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(model_pipeline=pipeline_rf,model_name=\"Random Forest\"):\n",
    "    \n",
    "    print(f\"Training {model_name} model\")\n",
    "\n",
    "    # Fit the model pipeline to the training set\n",
    "    #fitted_model = model_pipeline.fit(train_set)\n",
    "    fitted_model = train_model(model_pipeline)\n",
    "\n",
    "    print(\"Done\")\n",
    "    print(f\"Evaluating {model_name} model\")\n",
    "\n",
    "    # Evaluate the fitted model\n",
    "    train_accuracy, test_accuracy = evaluate_model(fitted_model)\n",
    "    print(\"Done\")\n",
    "    # Store the results\n",
    "    results= {\n",
    "            'fitted_model': fitted_model,\n",
    "            \"train_accuracy\": train_accuracy,\n",
    "            \"test_accuracy\": test_accuracy\n",
    "        }\n",
    "\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYDcrjUHBQHf"
   },
   "source": [
    "### 5. Call the function and interpret the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WyuTd4ijV1E"
   },
   "source": [
    "#### a. Training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "9T4JAj-QId2e",
    "outputId": "b7423773-bf83-489f-b21a-2fea8b04e7ad",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Random Forest model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/29 18:42:05 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/29 18:42:07 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/29 18:42:07 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/29 18:42:07 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/29 18:42:08 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "24/06/29 18:42:12 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "24/06/29 18:42:42 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "24/06/29 18:42:50 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/29 18:42:56 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/29 18:43:01 WARN DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/06/29 18:43:06 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/29 18:43:07 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "24/06/29 18:43:08 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/29 18:43:09 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/29 18:43:09 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/29 18:43:09 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/29 18:43:10 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "24/06/29 18:43:14 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "24/06/29 18:43:40 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "24/06/29 18:43:42 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/29 18:43:45 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/29 18:43:48 WARN DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/06/29 18:43:52 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/29 18:43:53 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "24/06/29 18:43:53 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/29 18:43:54 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/29 18:43:55 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/29 18:43:55 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/29 18:43:55 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "24/06/29 18:44:00 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "24/06/29 18:44:23 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "24/06/29 18:44:25 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/29 18:44:28 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/29 18:44:31 WARN DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/06/29 18:44:35 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/29 18:44:36 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "24/06/29 18:44:37 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/29 18:44:37 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "24/06/29 18:44:38 WARN DAGScheduler: Broadcasting large task binary with size 3.4 MiB\n",
      "24/06/29 18:44:42 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "24/06/29 18:45:05 WARN MemoryStore: Not enough space to cache rdd_338_116 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:05 WARN MemoryStore: Not enough space to cache rdd_338_117 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:05 WARN MemoryStore: Not enough space to cache rdd_338_109 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:05 WARN MemoryStore: Not enough space to cache rdd_338_122 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:05 WARN MemoryStore: Not enough space to cache rdd_338_100 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:05 WARN BlockManager: Persisting block rdd_338_117 to disk instead.\n",
      "24/06/29 18:45:05 WARN BlockManager: Persisting block rdd_338_109 to disk instead.\n",
      "24/06/29 18:45:05 WARN BlockManager: Persisting block rdd_338_100 to disk instead.\n",
      "24/06/29 18:45:05 WARN BlockManager: Persisting block rdd_338_122 to disk instead.\n",
      "24/06/29 18:45:05 WARN BlockManager: Persisting block rdd_338_116 to disk instead.\n",
      "24/06/29 18:45:05 WARN MemoryStore: Not enough space to cache rdd_338_114 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:05 WARN BlockManager: Persisting block rdd_338_114 to disk instead.\n",
      "24/06/29 18:45:05 WARN MemoryStore: Not enough space to cache rdd_338_119 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:05 WARN BlockManager: Persisting block rdd_338_119 to disk instead.\n",
      "24/06/29 18:45:05 WARN MemoryStore: Not enough space to cache rdd_338_121 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:05 WARN BlockManager: Persisting block rdd_338_121 to disk instead.\n",
      "24/06/29 18:45:05 WARN MemoryStore: Not enough space to cache rdd_338_115 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:05 WARN BlockManager: Persisting block rdd_338_115 to disk instead.\n",
      "24/06/29 18:45:05 WARN MemoryStore: Not enough space to cache rdd_338_123 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:05 WARN BlockManager: Persisting block rdd_338_123 to disk instead.\n",
      "24/06/29 18:45:05 WARN MemoryStore: Not enough space to cache rdd_338_118 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:05 WARN BlockManager: Persisting block rdd_338_118 to disk instead.\n",
      "24/06/29 18:45:06 WARN MemoryStore: Not enough space to cache rdd_338_110 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:06 WARN BlockManager: Persisting block rdd_338_110 to disk instead.\n",
      "24/06/29 18:45:06 WARN MemoryStore: Not enough space to cache rdd_338_107 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:06 WARN BlockManager: Persisting block rdd_338_107 to disk instead.\n",
      "24/06/29 18:45:06 WARN MemoryStore: Not enough space to cache rdd_338_127 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:06 WARN BlockManager: Persisting block rdd_338_127 to disk instead.\n",
      "24/06/29 18:45:06 WARN MemoryStore: Not enough space to cache rdd_338_120 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:06 WARN BlockManager: Persisting block rdd_338_120 to disk instead.\n",
      "24/06/29 18:45:06 WARN MemoryStore: Not enough space to cache rdd_338_113 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:06 WARN BlockManager: Persisting block rdd_338_113 to disk instead.\n",
      "24/06/29 18:45:06 WARN MemoryStore: Not enough space to cache rdd_338_126 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:06 WARN BlockManager: Persisting block rdd_338_126 to disk instead.\n",
      "24/06/29 18:45:06 WARN MemoryStore: Not enough space to cache rdd_338_125 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:06 WARN BlockManager: Persisting block rdd_338_125 to disk instead.\n",
      "24/06/29 18:45:06 WARN MemoryStore: Not enough space to cache rdd_338_129 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:06 WARN BlockManager: Persisting block rdd_338_129 to disk instead.\n",
      "24/06/29 18:45:06 WARN MemoryStore: Not enough space to cache rdd_338_131 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:06 WARN BlockManager: Persisting block rdd_338_131 to disk instead.\n",
      "24/06/29 18:45:06 WARN MemoryStore: Not enough space to cache rdd_338_124 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:06 WARN BlockManager: Persisting block rdd_338_124 to disk instead.\n",
      "24/06/29 18:45:07 WARN MemoryStore: Not enough space to cache rdd_338_130 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:07 WARN BlockManager: Persisting block rdd_338_130 to disk instead.\n",
      "24/06/29 18:45:07 WARN MemoryStore: Not enough space to cache rdd_338_128 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:07 WARN BlockManager: Persisting block rdd_338_128 to disk instead.\n",
      "24/06/29 18:45:13 WARN MemoryStore: Not enough space to cache rdd_338_136 in memory! (computed 717.9 MiB so far)\n",
      "24/06/29 18:45:13 WARN BlockManager: Persisting block rdd_338_136 to disk instead.\n",
      "24/06/29 18:45:13 WARN MemoryStore: Not enough space to cache rdd_338_148 in memory! (computed 717.9 MiB so far)\n",
      "24/06/29 18:45:13 WARN BlockManager: Persisting block rdd_338_148 to disk instead.\n",
      "24/06/29 18:45:13 WARN MemoryStore: Not enough space to cache rdd_338_129 in memory! (computed 315.2 MiB so far)\n",
      "24/06/29 18:45:13 WARN MemoryStore: Not enough space to cache rdd_338_110 in memory! (computed 475.6 MiB so far)\n",
      "24/06/29 18:45:13 WARN MemoryStore: Not enough space to cache rdd_338_123 in memory! (computed 475.6 MiB so far)\n",
      "24/06/29 18:45:13 WARN MemoryStore: Not enough space to cache rdd_338_119 in memory! (computed 475.6 MiB so far)\n",
      "24/06/29 18:45:13 WARN MemoryStore: Not enough space to cache rdd_338_134 in memory! (computed 717.9 MiB so far)\n",
      "24/06/29 18:45:13 WARN BlockManager: Persisting block rdd_338_134 to disk instead.\n",
      "24/06/29 18:45:13 WARN MemoryStore: Not enough space to cache rdd_338_142 in memory! (computed 717.9 MiB so far)\n",
      "24/06/29 18:45:13 WARN BlockManager: Persisting block rdd_338_142 to disk instead.\n",
      "24/06/29 18:45:13 WARN MemoryStore: Not enough space to cache rdd_338_146 in memory! (computed 717.9 MiB so far)\n",
      "24/06/29 18:45:13 WARN BlockManager: Persisting block rdd_338_146 to disk instead.\n",
      "24/06/29 18:45:13 WARN MemoryStore: Not enough space to cache rdd_338_151 in memory! (computed 717.9 MiB so far)\n",
      "24/06/29 18:45:13 WARN BlockManager: Persisting block rdd_338_151 to disk instead.\n",
      "24/06/29 18:45:13 WARN MemoryStore: Not enough space to cache rdd_338_147 in memory! (computed 717.9 MiB so far)\n",
      "24/06/29 18:45:13 WARN BlockManager: Persisting block rdd_338_147 to disk instead.\n",
      "24/06/29 18:45:13 WARN MemoryStore: Not enough space to cache rdd_338_124 in memory! (computed 209.6 MiB so far)\n",
      "24/06/29 18:45:13 WARN MemoryStore: Not enough space to cache rdd_338_145 in memory! (computed 717.9 MiB so far)\n",
      "24/06/29 18:45:13 WARN BlockManager: Persisting block rdd_338_145 to disk instead.\n",
      "24/06/29 18:45:13 WARN MemoryStore: Not enough space to cache rdd_338_125 in memory! (computed 315.2 MiB so far)\n",
      "24/06/29 18:45:13 WARN MemoryStore: Not enough space to cache rdd_338_137 in memory! (computed 717.9 MiB so far)\n",
      "24/06/29 18:45:13 WARN BlockManager: Persisting block rdd_338_137 to disk instead.\n",
      "24/06/29 18:45:13 WARN MemoryStore: Not enough space to cache rdd_338_107 in memory! (computed 475.6 MiB so far)\n",
      "24/06/29 18:45:13 WARN MemoryStore: Not enough space to cache rdd_338_117 in memory! (computed 717.9 MiB so far)\n",
      "24/06/29 18:45:13 WARN MemoryStore: Not enough space to cache rdd_338_120 in memory! (computed 475.6 MiB so far)\n",
      "24/06/29 18:45:13 WARN MemoryStore: Not enough space to cache rdd_338_118 in memory! (computed 717.9 MiB so far)\n",
      "24/06/29 18:45:13 WARN MemoryStore: Not enough space to cache rdd_338_130 in memory! (computed 475.6 MiB so far)\n",
      "24/06/29 18:45:13 WARN MemoryStore: Not enough space to cache rdd_338_114 in memory! (computed 475.6 MiB so far)\n",
      "24/06/29 18:45:13 WARN MemoryStore: Not enough space to cache rdd_338_128 in memory! (computed 315.2 MiB so far)\n",
      "24/06/29 18:45:13 WARN MemoryStore: Not enough space to cache rdd_338_126 in memory! (computed 475.6 MiB so far)\n",
      "24/06/29 18:45:13 WARN MemoryStore: Not enough space to cache rdd_338_113 in memory! (computed 475.6 MiB so far)\n",
      "24/06/29 18:45:13 WARN MemoryStore: Not enough space to cache rdd_338_131 in memory! (computed 475.6 MiB so far)\n",
      "24/06/29 18:45:13 WARN MemoryStore: Not enough space to cache rdd_338_141 in memory! (computed 717.9 MiB so far)\n",
      "24/06/29 18:45:13 WARN BlockManager: Persisting block rdd_338_141 to disk instead.\n",
      "24/06/29 18:45:15 WARN MemoryStore: Not enough space to cache rdd_338_149 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:15 WARN BlockManager: Persisting block rdd_338_149 to disk instead.\n",
      "24/06/29 18:45:15 WARN MemoryStore: Not enough space to cache rdd_338_150 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:15 WARN BlockManager: Persisting block rdd_338_150 to disk instead.\n",
      "24/06/29 18:45:15 WARN MemoryStore: Not enough space to cache rdd_338_115 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:17 WARN MemoryStore: Not enough space to cache rdd_338_163 in memory! (computed 315.2 MiB so far)\n",
      "24/06/29 18:45:17 WARN MemoryStore: Not enough space to cache rdd_338_161 in memory! (computed 315.2 MiB so far)\n",
      "24/06/29 18:45:17 WARN MemoryStore: Not enough space to cache rdd_338_153 in memory! (computed 475.6 MiB so far)\n",
      "24/06/29 18:45:17 WARN BlockManager: Persisting block rdd_338_161 to disk instead.\n",
      "24/06/29 18:45:17 WARN BlockManager: Persisting block rdd_338_163 to disk instead.\n",
      "24/06/29 18:45:17 WARN BlockManager: Persisting block rdd_338_153 to disk instead.\n",
      "24/06/29 18:45:17 WARN MemoryStore: Not enough space to cache rdd_338_165 in memory! (computed 315.2 MiB so far)\n",
      "24/06/29 18:45:17 WARN BlockManager: Persisting block rdd_338_165 to disk instead.\n",
      "24/06/29 18:45:17 WARN MemoryStore: Not enough space to cache rdd_338_162 in memory! (computed 315.2 MiB so far)\n",
      "24/06/29 18:45:17 WARN BlockManager: Persisting block rdd_338_162 to disk instead.\n",
      "24/06/29 18:45:17 WARN MemoryStore: Not enough space to cache rdd_338_166 in memory! (computed 315.2 MiB so far)\n",
      "24/06/29 18:45:17 WARN BlockManager: Persisting block rdd_338_166 to disk instead.\n",
      "24/06/29 18:45:17 WARN MemoryStore: Not enough space to cache rdd_338_167 in memory! (computed 315.2 MiB so far)\n",
      "24/06/29 18:45:17 WARN BlockManager: Persisting block rdd_338_167 to disk instead.\n",
      "24/06/29 18:45:17 WARN MemoryStore: Not enough space to cache rdd_338_154 in memory! (computed 475.6 MiB so far)\n",
      "24/06/29 18:45:17 WARN BlockManager: Persisting block rdd_338_154 to disk instead.\n",
      "24/06/29 18:45:17 WARN MemoryStore: Not enough space to cache rdd_338_155 in memory! (computed 475.6 MiB so far)\n",
      "24/06/29 18:45:17 WARN BlockManager: Persisting block rdd_338_155 to disk instead.\n",
      "24/06/29 18:45:17 WARN MemoryStore: Not enough space to cache rdd_338_157 in memory! (computed 475.6 MiB so far)\n",
      "24/06/29 18:45:17 WARN BlockManager: Persisting block rdd_338_157 to disk instead.\n",
      "24/06/29 18:45:17 WARN MemoryStore: Not enough space to cache rdd_338_158 in memory! (computed 475.6 MiB so far)\n",
      "24/06/29 18:45:17 WARN BlockManager: Persisting block rdd_338_158 to disk instead.\n",
      "24/06/29 18:45:19 WARN MemoryStore: Not enough space to cache rdd_338_136 in memory! (computed 315.2 MiB so far)\n",
      "24/06/29 18:45:19 WARN MemoryStore: Not enough space to cache rdd_338_141 in memory! (computed 136.5 MiB so far)\n",
      "24/06/29 18:45:19 WARN MemoryStore: Not enough space to cache rdd_338_142 in memory! (computed 209.6 MiB so far)\n",
      "24/06/29 18:45:19 WARN MemoryStore: Not enough space to cache rdd_338_137 in memory! (computed 209.6 MiB so far)\n",
      "24/06/29 18:45:19 WARN MemoryStore: Not enough space to cache rdd_338_147 in memory! (computed 209.6 MiB so far)\n",
      "24/06/29 18:45:19 WARN MemoryStore: Not enough space to cache rdd_338_146 in memory! (computed 136.5 MiB so far)\n",
      "24/06/29 18:45:19 WARN MemoryStore: Not enough space to cache rdd_338_148 in memory! (computed 136.5 MiB so far)\n",
      "24/06/29 18:45:19 WARN MemoryStore: Not enough space to cache rdd_338_150 in memory! (computed 315.2 MiB so far)\n",
      "24/06/29 18:45:19 WARN MemoryStore: Not enough space to cache rdd_338_145 in memory! (computed 209.6 MiB so far)\n",
      "24/06/29 18:45:19 WARN MemoryStore: Not enough space to cache rdd_338_134 in memory! (computed 209.6 MiB so far)\n",
      "24/06/29 18:45:19 WARN MemoryStore: Not enough space to cache rdd_338_164 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:19 WARN MemoryStore: Not enough space to cache rdd_338_160 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:19 WARN BlockManager: Persisting block rdd_338_164 to disk instead.\n",
      "24/06/29 18:45:19 WARN BlockManager: Persisting block rdd_338_160 to disk instead.\n",
      "24/06/29 18:45:20 WARN MemoryStore: Not enough space to cache rdd_338_151 in memory! (computed 717.9 MiB so far)\n",
      "24/06/29 18:45:20 WARN MemoryStore: Not enough space to cache rdd_338_149 in memory! (computed 717.9 MiB so far)\n",
      "24/06/29 18:45:23 WARN MemoryStore: Not enough space to cache rdd_338_164 in memory! (computed 315.2 MiB so far)\n",
      "24/06/29 18:45:23 WARN MemoryStore: Not enough space to cache rdd_338_160 in memory! (computed 209.6 MiB so far)\n",
      "24/06/29 18:45:23 WARN MemoryStore: Not enough space to cache rdd_338_153 in memory! (computed 717.9 MiB so far)\n",
      "24/06/29 18:45:23 WARN MemoryStore: Not enough space to cache rdd_338_166 in memory! (computed 209.6 MiB so far)\n",
      "24/06/29 18:45:23 WARN MemoryStore: Not enough space to cache rdd_338_161 in memory! (computed 136.5 MiB so far)\n",
      "24/06/29 18:45:23 WARN MemoryStore: Not enough space to cache rdd_338_163 in memory! (computed 88.5 MiB so far)\n",
      "24/06/29 18:45:23 WARN MemoryStore: Not enough space to cache rdd_338_167 in memory! (computed 209.6 MiB so far)\n",
      "24/06/29 18:45:23 WARN MemoryStore: Not enough space to cache rdd_338_154 in memory! (computed 717.9 MiB so far)\n",
      "24/06/29 18:45:23 WARN MemoryStore: Not enough space to cache rdd_338_162 in memory! (computed 475.6 MiB so far)\n",
      "24/06/29 18:45:24 WARN MemoryStore: Not enough space to cache rdd_338_155 in memory! (computed 717.9 MiB so far)\n",
      "24/06/29 18:45:24 WARN MemoryStore: Not enough space to cache rdd_338_165 in memory! (computed 1100.5 MiB so far)\n",
      "24/06/29 18:45:25 WARN DAGScheduler: Broadcasting large task binary with size 4.0 MiB\n",
      "24/06/29 18:45:28 WARN MemoryStore: Not enough space to cache rdd_338_119 in memory! (computed 88.5 MiB so far)\n",
      "24/06/29 18:45:28 WARN MemoryStore: Not enough space to cache rdd_338_107 in memory! (computed 315.2 MiB so far)\n",
      "24/06/29 18:45:28 WARN MemoryStore: Not enough space to cache rdd_338_120 in memory! (computed 136.5 MiB so far)\n",
      "24/06/29 18:45:28 WARN MemoryStore: Not enough space to cache rdd_338_114 in memory! (computed 209.6 MiB so far)\n",
      "24/06/29 18:45:28 WARN MemoryStore: Not enough space to cache rdd_338_113 in memory! (computed 209.6 MiB so far)\n",
      "24/06/29 18:45:28 WARN MemoryStore: Not enough space to cache rdd_338_118 in memory! (computed 136.5 MiB so far)\n",
      "24/06/29 18:45:28 WARN MemoryStore: Not enough space to cache rdd_338_117 in memory! (computed 136.5 MiB so far)\n",
      "24/06/29 18:45:28 WARN MemoryStore: Not enough space to cache rdd_338_110 in memory! (computed 209.6 MiB so far)\n",
      "24/06/29 18:45:28 WARN MemoryStore: Not enough space to cache rdd_338_125 in memory! (computed 56.5 MiB so far)\n",
      "24/06/29 18:45:28 WARN MemoryStore: Not enough space to cache rdd_338_124 in memory! (computed 56.5 MiB so far)\n",
      "24/06/29 18:45:28 WARN MemoryStore: Not enough space to cache rdd_338_115 in memory! (computed 136.5 MiB so far)\n",
      "24/06/29 18:45:28 WARN MemoryStore: Not enough space to cache rdd_338_123 in memory! (computed 56.5 MiB so far)\n",
      "24/06/29 18:45:29 WARN MemoryStore: Not enough space to cache rdd_338_128 in memory! (computed 315.2 MiB so far)\n",
      "24/06/29 18:45:29 WARN MemoryStore: Not enough space to cache rdd_338_129 in memory! (computed 315.2 MiB so far)\n",
      "24/06/29 18:45:29 WARN MemoryStore: Not enough space to cache rdd_338_131 in memory! (computed 315.2 MiB so far)\n",
      "24/06/29 18:45:29 WARN MemoryStore: Not enough space to cache rdd_338_130 in memory! (computed 315.2 MiB so far)\n",
      "24/06/29 18:45:30 WARN MemoryStore: Not enough space to cache rdd_338_148 in memory! (computed 16.5 MiB so far)\n",
      "24/06/29 18:45:30 WARN MemoryStore: Not enough space to cache rdd_338_126 in memory! (computed 717.9 MiB so far)\n",
      "24/06/29 18:45:30 WARN MemoryStore: Not enough space to cache rdd_338_147 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:30 WARN MemoryStore: Not enough space to cache rdd_338_136 in memory! (computed 209.6 MiB so far)\n",
      "24/06/29 18:45:30 WARN MemoryStore: Not enough space to cache rdd_338_145 in memory! (computed 56.5 MiB so far)\n",
      "24/06/29 18:45:30 WARN MemoryStore: Not enough space to cache rdd_338_141 in memory! (computed 88.5 MiB so far)\n",
      "24/06/29 18:45:30 WARN MemoryStore: Not enough space to cache rdd_338_149 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:30 WARN MemoryStore: Not enough space to cache rdd_338_151 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:30 WARN MemoryStore: Not enough space to cache rdd_338_150 in memory! (computed 16.5 MiB so far)\n",
      "24/06/29 18:45:30 WARN MemoryStore: Not enough space to cache rdd_338_142 in memory! (computed 88.5 MiB so far)\n",
      "24/06/29 18:45:30 WARN MemoryStore: Not enough space to cache rdd_338_146 in memory! (computed 56.5 MiB so far)\n",
      "24/06/29 18:45:30 WARN MemoryStore: Not enough space to cache rdd_338_134 in memory! (computed 315.2 MiB so far)\n",
      "24/06/29 18:45:30 WARN MemoryStore: Not enough space to cache rdd_338_137 in memory! (computed 315.2 MiB so far)\n",
      "24/06/29 18:45:30 WARN MemoryStore: Not enough space to cache rdd_338_155 in memory! (computed 136.5 MiB so far)\n",
      "24/06/29 18:45:30 WARN MemoryStore: Not enough space to cache rdd_338_153 in memory! (computed 475.6 MiB so far)\n",
      "24/06/29 18:45:31 WARN MemoryStore: Not enough space to cache rdd_338_160 in memory! (computed 209.6 MiB so far)\n",
      "24/06/29 18:45:31 WARN MemoryStore: Not enough space to cache rdd_338_164 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:31 WARN MemoryStore: Not enough space to cache rdd_338_161 in memory! (computed 136.5 MiB so far)\n",
      "24/06/29 18:45:31 WARN MemoryStore: Not enough space to cache rdd_338_166 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:31 WARN MemoryStore: Not enough space to cache rdd_338_165 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:31 WARN MemoryStore: Not enough space to cache rdd_338_167 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:31 WARN MemoryStore: Not enough space to cache rdd_338_162 in memory! (computed 315.2 MiB so far)\n",
      "24/06/29 18:45:31 WARN MemoryStore: Not enough space to cache rdd_338_163 in memory! (computed 315.2 MiB so far)\n",
      "24/06/29 18:45:33 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/29 18:45:35 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_338_123 in memory.\n",
      "24/06/29 18:45:35 WARN MemoryStore: Not enough space to cache rdd_338_114 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:35 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_338_125 in memory.\n",
      "24/06/29 18:45:35 WARN MemoryStore: Not enough space to cache rdd_338_115 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:35 WARN MemoryStore: Not enough space to cache rdd_338_113 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:35 WARN MemoryStore: Not enough space to cache rdd_338_125 in memory! (computed 688.0 B so far)\n",
      "24/06/29 18:45:35 WARN MemoryStore: Not enough space to cache rdd_338_123 in memory! (computed 688.0 B so far)\n",
      "24/06/29 18:45:35 WARN MemoryStore: Not enough space to cache rdd_338_117 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:35 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_338_124 in memory.\n",
      "24/06/29 18:45:35 WARN MemoryStore: Not enough space to cache rdd_338_119 in memory! (computed 16.5 MiB so far)\n",
      "24/06/29 18:45:35 WARN MemoryStore: Not enough space to cache rdd_338_120 in memory! (computed 16.5 MiB so far)\n",
      "24/06/29 18:45:35 WARN MemoryStore: Not enough space to cache rdd_338_124 in memory! (computed 688.0 B so far)\n",
      "24/06/29 18:45:35 WARN MemoryStore: Not enough space to cache rdd_338_107 in memory! (computed 56.5 MiB so far)\n",
      "24/06/29 18:45:35 WARN MemoryStore: Not enough space to cache rdd_338_110 in memory! (computed 88.5 MiB so far)\n",
      "24/06/29 18:45:35 WARN MemoryStore: Not enough space to cache rdd_338_118 in memory! (computed 88.5 MiB so far)\n",
      "24/06/29 18:45:35 WARN MemoryStore: Not enough space to cache rdd_338_129 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:35 WARN MemoryStore: Not enough space to cache rdd_338_126 in memory! (computed 88.5 MiB so far)\n",
      "24/06/29 18:45:35 WARN MemoryStore: Not enough space to cache rdd_338_128 in memory! (computed 136.5 MiB so far)\n",
      "24/06/29 18:45:35 WARN MemoryStore: Not enough space to cache rdd_338_130 in memory! (computed 88.5 MiB so far)\n",
      "24/06/29 18:45:36 WARN MemoryStore: Not enough space to cache rdd_338_131 in memory! (computed 209.6 MiB so far)\n",
      "24/06/29 18:45:36 WARN MemoryStore: Not enough space to cache rdd_338_136 in memory! (computed 16.5 MiB so far)\n",
      "24/06/29 18:45:36 WARN MemoryStore: Not enough space to cache rdd_338_134 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:36 WARN MemoryStore: Not enough space to cache rdd_338_141 in memory! (computed 88.5 MiB so far)\n",
      "24/06/29 18:45:36 WARN MemoryStore: Not enough space to cache rdd_338_142 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:36 WARN MemoryStore: Not enough space to cache rdd_338_137 in memory! (computed 209.6 MiB so far)\n",
      "24/06/29 18:45:37 WARN MemoryStore: Not enough space to cache rdd_338_148 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:37 WARN MemoryStore: Not enough space to cache rdd_338_150 in memory! (computed 16.5 MiB so far)\n",
      "24/06/29 18:45:37 WARN MemoryStore: Not enough space to cache rdd_338_146 in memory! (computed 56.5 MiB so far)\n",
      "24/06/29 18:45:37 WARN MemoryStore: Not enough space to cache rdd_338_149 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:37 WARN MemoryStore: Not enough space to cache rdd_338_147 in memory! (computed 88.5 MiB so far)\n",
      "24/06/29 18:45:37 WARN MemoryStore: Not enough space to cache rdd_338_151 in memory! (computed 56.5 MiB so far)\n",
      "24/06/29 18:45:37 WARN MemoryStore: Not enough space to cache rdd_338_145 in memory! (computed 136.5 MiB so far)\n",
      "24/06/29 18:45:37 WARN MemoryStore: Not enough space to cache rdd_338_155 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:37 WARN MemoryStore: Not enough space to cache rdd_338_153 in memory! (computed 88.5 MiB so far)\n",
      "24/06/29 18:45:38 WARN MemoryStore: Not enough space to cache rdd_338_162 in memory! (computed 56.5 MiB so far)\n",
      "24/06/29 18:45:38 WARN MemoryStore: Not enough space to cache rdd_338_160 in memory! (computed 88.5 MiB so far)\n",
      "24/06/29 18:45:38 WARN MemoryStore: Not enough space to cache rdd_338_165 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:38 WARN MemoryStore: Not enough space to cache rdd_338_164 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:38 WARN MemoryStore: Not enough space to cache rdd_338_161 in memory! (computed 88.5 MiB so far)\n",
      "24/06/29 18:45:38 WARN MemoryStore: Not enough space to cache rdd_338_167 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:38 WARN MemoryStore: Not enough space to cache rdd_338_166 in memory! (computed 16.5 MiB so far)\n",
      "24/06/29 18:45:38 WARN MemoryStore: Not enough space to cache rdd_338_163 in memory! (computed 16.5 MiB so far)\n",
      "24/06/29 18:45:41 WARN DAGScheduler: Broadcasting large task binary with size 4.1 MiB\n",
      "24/06/29 18:45:43 WARN MemoryStore: Not enough space to cache rdd_338_123 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:43 WARN MemoryStore: Not enough space to cache rdd_338_124 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:43 WARN MemoryStore: Not enough space to cache rdd_338_110 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:43 WARN MemoryStore: Not enough space to cache rdd_338_125 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:43 WARN MemoryStore: Not enough space to cache rdd_338_120 in memory! (computed 16.5 MiB so far)\n",
      "24/06/29 18:45:43 WARN MemoryStore: Not enough space to cache rdd_338_126 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:43 WARN MemoryStore: Not enough space to cache rdd_338_114 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:43 WARN MemoryStore: Not enough space to cache rdd_338_115 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:43 WARN MemoryStore: Not enough space to cache rdd_338_113 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:43 WARN MemoryStore: Not enough space to cache rdd_338_129 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:43 WARN MemoryStore: Not enough space to cache rdd_338_117 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:43 WARN MemoryStore: Not enough space to cache rdd_338_119 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:43 WARN MemoryStore: Not enough space to cache rdd_338_130 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:43 WARN MemoryStore: Not enough space to cache rdd_338_107 in memory! (computed 56.5 MiB so far)\n",
      "24/06/29 18:45:43 WARN MemoryStore: Not enough space to cache rdd_338_131 in memory! (computed 56.5 MiB so far)\n",
      "24/06/29 18:45:43 WARN MemoryStore: Not enough space to cache rdd_338_118 in memory! (computed 88.5 MiB so far)\n",
      "24/06/29 18:45:43 WARN MemoryStore: Not enough space to cache rdd_338_128 in memory! (computed 209.6 MiB so far)\n",
      "24/06/29 18:45:44 WARN MemoryStore: Not enough space to cache rdd_338_136 in memory! (computed 56.5 MiB so far)\n",
      "24/06/29 18:45:44 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_338_148 in memory.\n",
      "24/06/29 18:45:44 WARN MemoryStore: Not enough space to cache rdd_338_147 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:44 WARN MemoryStore: Not enough space to cache rdd_338_146 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:44 WARN MemoryStore: Not enough space to cache rdd_338_137 in memory! (computed 56.5 MiB so far)\n",
      "24/06/29 18:45:44 WARN MemoryStore: Not enough space to cache rdd_338_148 in memory! (computed 688.0 B so far)\n",
      "24/06/29 18:45:44 WARN MemoryStore: Not enough space to cache rdd_338_145 in memory! (computed 16.5 MiB so far)\n",
      "24/06/29 18:45:44 WARN MemoryStore: Not enough space to cache rdd_338_141 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:44 WARN MemoryStore: Failed to reserve initial memory threshold of 1024.0 KiB for computing block rdd_338_149 in memory.\n",
      "24/06/29 18:45:44 WARN MemoryStore: Not enough space to cache rdd_338_149 in memory! (computed 688.0 B so far)\n",
      "24/06/29 18:45:44 WARN MemoryStore: Not enough space to cache rdd_338_151 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:44 WARN MemoryStore: Not enough space to cache rdd_338_150 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:44 WARN MemoryStore: Not enough space to cache rdd_338_142 in memory! (computed 88.5 MiB so far)\n",
      "24/06/29 18:45:44 WARN MemoryStore: Not enough space to cache rdd_338_134 in memory! (computed 136.5 MiB so far)\n",
      "24/06/29 18:45:44 WARN MemoryStore: Not enough space to cache rdd_338_153 in memory! (computed 136.5 MiB so far)\n",
      "24/06/29 18:45:44 WARN MemoryStore: Not enough space to cache rdd_338_155 in memory! (computed 88.5 MiB so far)\n",
      "24/06/29 18:45:46 WARN MemoryStore: Not enough space to cache rdd_338_163 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:46 WARN MemoryStore: Not enough space to cache rdd_338_161 in memory! (computed 56.5 MiB so far)\n",
      "24/06/29 18:45:46 WARN MemoryStore: Not enough space to cache rdd_338_164 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:46 WARN MemoryStore: Not enough space to cache rdd_338_160 in memory! (computed 88.5 MiB so far)\n",
      "24/06/29 18:45:46 WARN MemoryStore: Not enough space to cache rdd_338_165 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:46 WARN MemoryStore: Not enough space to cache rdd_338_167 in memory! (computed 56.5 MiB so far)\n",
      "24/06/29 18:45:46 WARN MemoryStore: Not enough space to cache rdd_338_166 in memory! (computed 56.5 MiB so far)\n",
      "24/06/29 18:45:46 WARN MemoryStore: Not enough space to cache rdd_338_162 in memory! (computed 209.6 MiB so far)\n",
      "24/06/29 18:45:49 WARN DAGScheduler: Broadcasting large task binary with size 4.2 MiB\n",
      "24/06/29 18:45:51 WARN MemoryStore: Not enough space to cache rdd_338_124 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:51 WARN MemoryStore: Not enough space to cache rdd_338_125 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:51 WARN MemoryStore: Not enough space to cache rdd_338_123 in memory! (computed 16.5 MiB so far)\n",
      "24/06/29 18:45:51 WARN MemoryStore: Not enough space to cache rdd_338_107 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:51 WARN MemoryStore: Not enough space to cache rdd_338_126 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:51 WARN MemoryStore: Not enough space to cache rdd_338_114 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:51 WARN MemoryStore: Not enough space to cache rdd_338_110 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:51 WARN MemoryStore: Not enough space to cache rdd_338_113 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:51 WARN MemoryStore: Not enough space to cache rdd_338_115 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:51 WARN MemoryStore: Not enough space to cache rdd_338_128 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:51 WARN MemoryStore: Not enough space to cache rdd_338_119 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:51 WARN MemoryStore: Not enough space to cache rdd_338_118 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:51 WARN MemoryStore: Not enough space to cache rdd_338_117 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:51 WARN MemoryStore: Not enough space to cache rdd_338_120 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:51 WARN MemoryStore: Not enough space to cache rdd_338_130 in memory! (computed 56.5 MiB so far)\n",
      "24/06/29 18:45:51 WARN MemoryStore: Not enough space to cache rdd_338_131 in memory! (computed 56.5 MiB so far)\n",
      "24/06/29 18:45:51 WARN MemoryStore: Not enough space to cache rdd_338_129 in memory! (computed 209.6 MiB so far)\n",
      "24/06/29 18:45:51 WARN MemoryStore: Not enough space to cache rdd_338_142 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:51 WARN MemoryStore: Not enough space to cache rdd_338_141 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:51 WARN MemoryStore: Not enough space to cache rdd_338_136 in memory! (computed 56.5 MiB so far)\n",
      "24/06/29 18:45:52 WARN MemoryStore: Not enough space to cache rdd_338_145 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:52 WARN MemoryStore: Not enough space to cache rdd_338_150 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:52 WARN MemoryStore: Not enough space to cache rdd_338_151 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:52 WARN MemoryStore: Not enough space to cache rdd_338_147 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:52 WARN MemoryStore: Not enough space to cache rdd_338_148 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:52 WARN MemoryStore: Not enough space to cache rdd_338_149 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:52 WARN MemoryStore: Not enough space to cache rdd_338_153 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:52 WARN MemoryStore: Not enough space to cache rdd_338_146 in memory! (computed 16.5 MiB so far)\n",
      "24/06/29 18:45:52 WARN MemoryStore: Not enough space to cache rdd_338_137 in memory! (computed 88.5 MiB so far)\n",
      "24/06/29 18:45:52 WARN MemoryStore: Not enough space to cache rdd_338_155 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:52 WARN MemoryStore: Not enough space to cache rdd_338_134 in memory! (computed 209.6 MiB so far)\n",
      "24/06/29 18:45:53 WARN MemoryStore: Not enough space to cache rdd_338_162 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:53 WARN MemoryStore: Not enough space to cache rdd_338_163 in memory! (computed 8.5 MiB so far)\n",
      "24/06/29 18:45:53 WARN MemoryStore: Not enough space to cache rdd_338_161 in memory! (computed 88.5 MiB so far)\n",
      "24/06/29 18:45:53 WARN MemoryStore: Not enough space to cache rdd_338_164 in memory! (computed 32.5 MiB so far)\n",
      "24/06/29 18:45:53 WARN MemoryStore: Not enough space to cache rdd_338_160 in memory! (computed 209.6 MiB so far)\n",
      "24/06/29 18:45:53 WARN MemoryStore: Not enough space to cache rdd_338_166 in memory! (computed 16.5 MiB so far)\n",
      "24/06/29 18:45:53 WARN MemoryStore: Not enough space to cache rdd_338_167 in memory! (computed 88.5 MiB so far)\n",
      "24/06/29 18:45:53 WARN MemoryStore: Not enough space to cache rdd_338_165 in memory! (computed 136.5 MiB so far)\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Evaluating Random Forest model\n",
      "Making predictions on the training set\n",
      "Making predictions on the test set\n",
      "Evaluating the model on training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/06/29 18:45:57 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n",
      "24/06/29 18:45:58 WARN DAGScheduler: Broadcasting large task binary with size 2.2 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the model on test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 166:===========================================>        (141 + 27) / 168]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.2393535072214005\n",
      "Test accuracy: 0.23688275756061944\n",
      "Done\n",
      "Duration: 244.44258093833923 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'fitted_model': PipelineModel_485696d14a3b,\n",
       " 'train_accuracy': 0.2393535072214005,\n",
       " 'test_accuracy': 0.23688275756061944}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "start=time.time()\n",
    "results = train_and_evaluate_model()\n",
    "end=time.time()\n",
    "print('Duration:',end-start,'seconds')\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DqVehK6LjV1F"
   },
   "source": [
    "#### b. Results interpretetion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We remark that:\n",
    "- The Random Forest model shows very poor performance on both the training and test sets, with accuracies below 24%. This indicates that the model is not capturing the patterns in the data effectively.\n",
    "Given the very low performance of the Random Forest model, it is not worthwhile to spend significant effort on tuning its hyperparameters. Instead, it is better to try other feature engineering methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADKEJXPm1-cu"
   },
   "source": [
    "Let us use Grid search with cross validation to find the best regularisation parameter. We will use 10 values of regularisation parameter varing in a log scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAWi0NqwSzgp"
   },
   "source": [
    "### 1. Pipeline creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-23T01:39:53.411702Z",
     "iopub.status.busy": "2024-06-23T01:39:53.410772Z",
     "iopub.status.idle": "2024-06-23T01:39:53.430237Z",
     "shell.execute_reply": "2024-06-23T01:39:53.429336Z",
     "shell.execute_reply.started": "2024-06-23T01:39:53.411652Z"
    },
    "id": "Wtq5K0JbOdpD",
    "outputId": "00a6afd5-4bf2-4ff2-edea-9f1c976d24fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline_1aed6fc0d3d6"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Define parameter grids for Random Forest\n",
    "paramGrid_rf = ParamGridBuilder() \\\n",
    "    .addGrid(rf.maxDepth, [20, 25, 30]) \\\n",
    "    .addGrid(rf.numTrees, [50, 100, 150]) \\\n",
    "    .build()\n",
    "\n",
    "# Create Cross-validation for Random Forest\n",
    "cv_rf = CrossValidator(estimator=rf, estimatorParamMaps=paramGrid_rf,\n",
    "                       evaluator=MulticlassClassificationEvaluator(labelCol=\"category_label\", predictionCol=\"prediction\", metricName=\"accuracy\"),\n",
    "                       numFolds=3, parallelism=1)\n",
    "\n",
    "# Create pipeline for Random Forest\n",
    "pipeline_rf = Pipeline(stages=[hashingTF,idf, cv_rf])\n",
    "\n",
    "pipeline_rf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8vJUT2CTjV1G"
   },
   "source": [
    "### 3. Interpreting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W4dR1ws92gZ6"
   },
   "source": [
    "We remark that:\n",
    "- The Random Forest model shows very poor performance on both the training and test sets, with accuracies below 24%. This indicates that the model is not capturing the patterns in the data effectively.\n",
    "Given the very low performance of the Random Forest model, it is not worthwhile to spend significant effort on tuning its hyperparameters. Instead, it is better to try other feature engineering methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnFsw8x5Vyy2"
   },
   "source": [
    "## VII - Summary\n",
    "\n",
    "### Random Forest Model Performance\n",
    "\n",
    "- **Random Forest with HashingTF**:\n",
    "  - Train Accuracy: 24%\n",
    "  - Test Accuracy: 24%\n",
    "\n",
    "### Analysis\n",
    "\n",
    "The Random Forest model shows very poor performance on both the training and test sets, indicating it does not effectively capture data patterns. It's advisable to explore alternative feature engineering methods or more complex models for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "NSyD5awwBByb",
    "outputId": "53219ebe-67ca-4b28-a0b7-1d6d7554d132"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[category_label: double, description_filtered: array<string>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the cache\n",
    "df.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "FbaTgrZajV1H"
   },
   "outputs": [],
   "source": [
    "# Stop the spark session\n",
    "#spark.stop()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 551982,
     "sourceId": 3756201,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5226348,
     "sourceId": 8761839,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30162,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "rf_env",
   "language": "python",
   "name": "rf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
